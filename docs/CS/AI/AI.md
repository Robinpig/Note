## Introduction




在 2017 年 NeurIPS 会议上，谷歌研究人员在他们的里程碑式论文《Attention Is All You Need》中介绍了Transformer架构

 [LLM](/docs/CS/AI/LLM/LLM.md) 


## Links







