## Introduction


检索增强生成（RAG）是指对大型语言模型输出进行优化，使其能够在生成响应之前引用训练数据来源之外的权威知识库
LLM 面临的已知挑战包括：
在没有答案的情况下提供虚假信息。
当用户需要特定的当前响应时，提供过时或通用的信息。
从非权威来源创建响应。
由于术语混淆，不同的培训来源使用相同的术语来谈论不同的事情，因此会产生不准确的响应。

RAG 是解决其中一些挑战的一种方法。它会重定向 LLM，从权威的、预先确定的知识来源中检索相关信息。组织可以更好地控制生成的文本输出，并且用户可以深入了解 LLM 如何生成响应
一个简单的 RAG 流程主要包含三个部分：
索引器 Indexer: 解析文档，对文档做切片并向量化，存储在向量数据库中。
检索器 Retriever: ，从向量库中检索与问题最相关的 top-N 文本切片。
生成器 Generator: 根据检索到的文本切片生成回答。
为什么要这么做？本质上还是因为“知识”太多，大模型的上下文放不下，因此需要提前筛选出相关的内容。但由于筛选的过程是很耗时的（不管是因为数量太大，还是筛选的逻辑很复杂），因此需要提前建立索

















## Links