## Introduction

Consensus is a fundamental problem in fault-tolerant distributed systems.
Consensus involves multiple servers agreeing on values. Once they reach a decision on a value, that decision is final.
Typical consensus algorithms make progress when any majority of their servers is available; for example, a cluster of 5 servers can continue to operate even if 2 servers fail.
If more servers fail, they stop making progress (but will never return an incorrect result).

Consensus typically arises in the context of replicated state machines, a general approach to building fault-tolerant systems.
Each server has a state machine and a log. The state machine is the component that we want to make fault-tolerant, such as a hash table.
It will appear to clients that they are interacting with a single, reliable state machine, even if a minority of the servers in the cluster fail.
Each state machine takes as input commands from its log. In our hash table example, the log would include commands like set x to 3.
A consensus algorithm is used to agree on the commands in the servers' logs.
The consensus algorithm must ensure that if any state machine applies set x to 3 as the nth command, no other state machine will ever apply a different nth command.
As a result, each state machine processes the same series of commands and thus produces the same series of results and arrives at the same series of states.

A fundamental problem in distributed computing and multi-agent systems is to achieve overall system reliability in the presence of a number of faulty processes.
This often requires coordinating processes to reach consensus, or agree on some data value that is needed during computation.
Example applications of consensus include agreeing on what transactions to commit to a database in which order, state machine replication, and atomic broadcasts.
Real-world applications often requiring consensus include cloud computing, clock synchronization, PageRank, opinion formation, smart power grids, state estimation, control of UAVs (and multiple robots/agents in general), load balancing, blockchain, and others.

## Problem description

The consensus problem requires agreement among a number of processes (or agents) for a single data value.
Some of the processes (agents) may fail or be unreliable in other ways, so consensus protocols must be fault tolerant or resilient.
The processes must somehow put forth their candidate values, communicate with one another, and agree on a single consensus value.

The consensus problem is a fundamental problem in control of multi-agent systems.
One approach to generating consensus is for all processes (agents) to agree on a majority value.
In this context, a majority requires at least one more than half of available votes (where each process is given a vote).
However, one or more faulty processes may skew the resultant outcome such that consensus may not be reached or reached incorrectly.

Protocols that solve consensus problems are designed to deal with limited numbers of faulty processes.
These protocols must satisfy a number of requirements to be useful. For instance, a trivial protocol could have all processes output binary value 1.
This is not useful and thus the requirement is modified such that the output must somehow depend on the input. That is, the output value of a consensus protocol must be the input value of some process.
Another requirement is that a process may decide upon an output value only once and this decision is irrevocable. A process is called correct in an execution if it does not experience a failure.
A consensus protocol tolerating halting failures must satisfy the following properties.

- **Termination**
  Eventually, every correct process decides some value.
- **Integrity**
  If all the correct processes proposed the same value v, then any correct process must decide v.
- **Agreement**
  Every correct process must agree on the same value.

Variations on the definition of integrity may be appropriate, according to the application.
For example, a weaker type of integrity would be for the decision value to equal a value that some correct process proposed – not necessarily all of them.
The Integrity condition is also known as validity in the literature.

A protocol that can correctly guarantee consensus amongst n processes of which at most t fail is said to be t-resilient.

In evaluating the performance of consensus protocols two factors of interest are running time and message complexity.
Running time is given in Big O notation in the number of rounds of message exchange as a function of some input parameters (typically the number of processes and/or the size of the input domain).
Message complexity refers to the amount of message traffic that is generated by the protocol.
Other factors may include memory usage and the size of messages.

## Models of computation

Varying models of computation may define a "consensus problem". Some models may deal with fully connected graphs, while others may deal with rings and trees.
In some models message authentication is allowed, whereas in others processes are completely anonymous. Shared memory models in which processes communicate by accessing objects in shared memory are also an important area of research.

### Communication channels with direct or transferable authentication

In most models of communication protocol participants communicate through authenticated channels.
This means that messages are not anonymous, and receivers know the source of every message they receive.
Some models assume a stronger, transferable form of authentication, where each message is signed by the sender, so that a receiver knows not just the immediate source of every message, but the participant that initially created the message.
This stronger type of authentication is achieved by digital signatures, and when this stronger form of authentication is available, protocols can tolerate a larger number of faults.

The two different authentication models are often called oral communication and written communication models.
In an oral communication model, the immediate source of information is known, whereas in stronger, written communication models, every step along the receiver learns not just the immediate source of the message, but the communication history of the message.

### Inputs and outputs of consensus

In the most traditional single-value consensus protocols such as Paxos, cooperating nodes agree on a single value such as an integer, which may be of variable size so as to encode useful metadata such as a transaction committed to a database.

A special case of the single-value consensus problem, called binary consensus, restricts the input, and hence the output domain, to a single binary digit {0,1}.
While not highly useful by themselves, binary consensus protocols are often useful as building blocks in more general consensus protocols, especially for asynchronous consensus.

In multi-valued consensus protocols such as Multi-Paxos and Raft, the goal is to agree on not just a single value but a series of values over time, forming a progressively-growing history.
While multi-valued consensus may be achieved naively by running multiple iterations of a single-valued consensus protocol in succession, many optimizations and other considerations such as reconfiguration support can make multi-valued consensus protocols more efficient in practice.

## Crash and Byzantine failures

There are two types of failures a process may undergo, a crash failure or a Byzantine failure.
A crash failure occurs when a process abruptly stops and does not resume.
Byzantine failures are failures in which absolutely no conditions are imposed.
For example, they may occur as a result of the malicious actions of an adversary.
A process that experiences a Byzantine failure may send contradictory or conflicting data to other processes, or it may sleep and then resume activity after a lengthy delay.
Of the two types of failures, Byzantine failures are far more disruptive.

Thus, a consensus protocol tolerating Byzantine failures must be resilient to every possible error that can occur.

A stronger version of consensus tolerating Byzantine failures is given by strengthening the Integrity constraint:

**Integrity**
If a correct process decides v, then v must have been proposed by some correct process.

### Asynchronous and synchronous systems

The consensus problem may be considered in the case of asynchronous or synchronous systems.
While real world communications are often inherently asynchronous, it is more practical and often easier to model synchronous systems, given that asynchronous systems naturally involve more issues than synchronous ones.

In synchronous systems, it is assumed that all communications proceed in rounds. In one round, a process may send all the messages it requires, while receiving all messages from other processes.
In this manner, no message from one round may influence any messages sent within the same round.



## FLP Impossibility

Paper [Impossibility of Distributed Consensuswith One Faulty Process](https://dl.acm.org/doi/pdf/10.1145/3149.214121) assumes that processing is entirely asynchronous; there’s no shared notion of time between the processes.
Algorithms in such systems cannot be based on timeouts, and there’s no way for a process to find out whether the other process has crashed or is simply running too slow.
Given these assumptions, there exists no protocol that can guarantee consensus in a bounded time.
No completely asynchronous consensus algorithm can tolerate the unannounced crash of even a single remote process.

If we do not consider an upper time bound for the process to complete the algorithm steps, process failures can’t be reliably detected, and there’s no deterministic algorithm to reach a consensus.
It means that we cannot always reach consensus in an asynchronous system in bounded time.
In practice, systems exhibit at least some degree of synchrony, and the solution to this problem requires a more refined model.

It is not always possible to solve a consensus problem in an asynchronous model.
Moreover, designing an efficient synchronous algorithm is not always achievable, and for some tasks the practical solutions are more likely to be time-dependent [Efficiency of Synchronous Versus Asynchronous Distributed Systems](https://dl.acm.org/doi/pdf/10.1145/2402.322387).

- Failure Models
- Crash Faults
- Omission Faults

This model assumes that the process skips some of the algorithm steps, or is not able to execute them, or this execution is not visible to other participants, or it cannot send or receive messages to and from other participants.

Omission fault captures network partitions between the processes caused by faulty network links, switch failures, or network congestion.
Network partitions can be represented as omissions of messages between individual processes or process groups.
A crash can be simulated by completely omitting any messages to and from the process.

Arbitrary Faults


Avoid FLP:

- Fault Masking
- Failure Detectors
- Non-Determinism


In a fully asynchronous message-passing distributed system, in which at least one process may have a crash failure, it has been proven in the famous FLP impossibility result that a deterministic algorithm for achieving consensus is impossible.
This impossibility result derives from worst-case scheduling scenarios, which are unlikely to occur in practice except in adversarial situations such as an intelligent denial-of-service attacker in the network.
In most normal situations, process scheduling has a degree of natural randomness.

In an asynchronous model, some forms of failures can be handled by a synchronous consensus protocol.
For instance, the loss of a communication link may be modeled as a process which has suffered a Byzantine failure.

Randomized consensus algorithms can circumvent the FLP impossibility result by achieving both safety and liveness with overwhelming probability,
even under worst-case scheduling scenarios such as an intelligent denial-of-service attacker in the network.


### Failure Detectors

properties of failure detectors:

- Completeness
- Accuracy


Eventually Weakly Failure Detector

- Eventually Weakly Complete
- Eventually Weakly Accurate





## Permissioned versus permissionless consensus

Consensus algorithms traditionally assume that the set of participating nodes is fixed and given at the outset:
that is, that some prior (manual or automatic) configuration process has permissioned a particular known group of participants who can authenticate each other as members of the group.
In the absence of such a well-defined, closed group with authenticated members, a Sybil attack against an open consensus group can defeat even a Byzantine consensus algorithm,
simply by creating enough virtual participants to overwhelm the fault tolerance threshold.

A permissionless consensus protocol, in contrast, allows anyone in the network to join dynamically and participate without prior permission,
but instead imposes a different form of artificial cost or barrier to entry to mitigate the Sybil attack threat.
Bitcoin introduced the first permissionless consensus protocol using proof of work and a difficulty adjustment function, in which participants compete to solve cryptographic hash puzzles,
and probabilistically earn the right to commit blocks and earn associated rewards in proportion to their invested computational effort.
Motivated in part by the high energy cost of this approach, subsequent permissionless consensus protocols have proposed or adopted other alternative participation rules for Sybil attack protection,
such as proof of stake, proof of space, and proof of authority.

[Consensus in the Presence of Partial Synchrony](https://dl.acm.org/doi/pdf/10.1145/42282.42283)



## Consensus Algorithms

[Paxos](/docs/CS/Distributed/Paxos.md) is a family of distributed algorithms used to reach consensus.

[Raft](/docs/CS/Distributed/Raft.md) is a consensus algorithm that is designed to be easy to understand.


PBFT


## Links

- [Distributed Systems](/docs/CS/Distributed/Distributed_Systems.md)

## References

1. [How to Build a Highly Available System Using Consensus](https://www.microsoft.com/en-us/research/uploads/prod/1996/10/Acrobat-58-Copy.pdf)
