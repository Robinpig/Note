## Introduction

钉钉的技术栈继承自阿里巴巴集团 阿里有“大中台,小前台”的组织战略 所以钉钉在大的框架上是复用集团的能力 包括中间件、存储引擎、微服务框架等 
在此之上，钉钉聚焦在核心能力的研发，比如：IM 核心系统、系统单元化、音视频通讯，弱网优化，图片收发极致体验等等

钉钉作为 ToB 产品，业务场景跟 ToC 的 IM 产品有很大区别，架构上也各有侧重

在钉钉里，企业的组织关系映射到 IM 的群，产生了为数众多的超级大群。和 500 群人数上限相比，钉钉支持万人大群，大幅提升了群的触达人数。

如此数目繁多的万人群给 IM 系统的流量冲击巨大。在节假日，特别是元旦、春节或者双 11 这样的重大活动时期，管理层和员工在大群高频互动，流量洪峰瞬间流过 IM 系统，挑战着系统的极限

为支撑好超级大群，我们做了以下多点的优化

- 降低存储扩散量
  最早 IM 使用写扩散模型，一万人的群发一条消息写一万次消息收件箱。优化为读扩散模型后，一条消息只需写一次消息收件箱，扩散量降低到万分之一
- 智能限流
  在节日场景下，一些大群的消息发送频率过高，可能超过系统整体容量，影响 IM 系统稳定性。如果对每个群设置较低的发送阈值，系统又没有完全发挥出容量，从而提供足够流畅的用户体验。针对这个问题，我们设计了一种智能限流的方法，当总体流量超过系统阈值时，自动根据当时情况对消息发送频率相对较高的大群进行限流
- 万人群成员多级缓存
  我们在客户端、服务端建立了群成员的多级缓存
  一方面会增加服务端的请求压力 避免了大量群成员读写对 DB 的压力。如果压力直接打到 DB 层，万行记录的扩散量过大，很容易造成热点，影响系统稳定性，另一方面输入@后弹出群成员列表的动作也会因网络操作延迟 用户能感受到长达数十秒的卡顿，因此在客户端也实现了一层缓存，
  记录了群组资料的数据
  但是增加客户端缓存又可能造成群成员列表更新不及时的问题，因此我们还增加了一个「最后更新时间」的记录值，
  这个值会在每次有群成员列表更新的动作(如打开App时同步群组、查看群资料、群组更新主动通知)时更新。
  当触发@操作时，会去检查这个最后更新时间是否超过限定值，如果超过就需要调用群组接口获取数据并更新本地缓存，
  如果未超过就直接使用本地缓存，通过这样平衡服务端请求压力与数据更新不及时的问题
  
- 端到端的体验保证
  客户端定期做极限压测，在群消息大规模刷屏的情况，保证用户体验流畅不卡顿



钉钉中的历史消息是可回溯的。在 ToB 场景下，数据属于企业的资产。企业有需求查看历史消息，因为它是关键的沟通信息

- 首先是既省流量，又不遗漏的历史消息回溯协议：最近的消息通过同步协议推送到达客户端本地。而历史的消息，服务端不曾推送，客户端本地没有入库。
  在用户进入会话时，如果客户端发现本地消息不足，自动从服务端拉取不足的历史消息。采用这种推拉结合的协议，保证了消息不管多么久远，都可以毫无遗漏的从服务端同步下来
- 然后是低成本的历史消息存储架构：消息具有典型的冷热属性: 用户访问的绝大部分都是最近的数据。我们自研了一套冷热分离架构，在冷库使用低成本高压缩率的存储引擎，大幅下降存储成本。
- 最后是达到金融级安全保障的历史消息加密：为了保证历史消息的安全性，我们在全链路使用金融级的加密算法，不留死角，确保没有任何人可以非法获取历史消息



### 场景化

ToC IM 产品的场景都比较通用。比如微信群，每个人能够使用的功能集合是一样的，大家进群聊天，都可以改群昵称，群名称。

钉钉则是面向场景打造极致体验。以班级群为例，班级群里面没有用户的概念，变成了老师、家长、学生。进群后家长无法修改群昵称，完全由系统设置，比如"小明爸爸"。
所以，班级群的进群路径、群管理、昵称展示，都是面向家校沟通场景的特殊优化，目的是做到家校场景的极致用户体验。

这给技术团队带来两方面的挑战。一方面是系统模型必须做到可扩展性强，足够灵活，能够快速地支持业务场景化的需求；另一方面是在维持业务快速迭代的情况下，保持核心 IM 系统的高可用性
因此钉钉的架构必须做到同时满足这两点需求。

还是以班级群为例。它使用小程序开发，不需要发版就可以做 bugfix、实现业务需求。
同时服务端切分为了业务层和 IMCore 层。业务层做灵活多变的业务逻辑，迭代速度快。
IMCore 层提供基础能力和扩展点，改动频次低，主要是提供高稳定性和单元化能力。
服务分层后，基本做到了新需求不改动 IMCore 层。迭代速度快，系统稳定性强，达到了业务、技术皆大欢喜的局面

单元化在钉钉有多层需求。

高可用：钉钉要保证 vip 用户在地域灾难的情况下可用。因此我们设计了一套基于单元化的异地容灾方案。
当中心宕机，两分钟内一键把 vip 用户调度到容灾单元，确保用户能够正常使用 IM 基本功能。

国际化：海外地区的对于数据有合规的要求。同时，钉钉在当地部署应用，也给海外用户提供了更流畅的用户体验。

支持大客户及特殊行业：钉钉今天不仅承接中小企业的沟通办公，也承接不少政务大客户。他们对钉钉的诉求是具备专有云部署能力。

容量：随着业务发展，所有流量在中心处理不可扩展。把流量分散到多地域是一个必然选择。

钉钉通过一套代码部署，一套运维体系实现单元化，满足了以上多层次的需求。
我们开发了单元化基础组件，动态路由，业务层数据同步组件等一系列基础设施，可以将钉钉部署在任何一个国家或地区，甚至客户的自有机房



## Architecture

低延迟、高触达、高可用一直是 DTIM 设计的第一原则，依据这个原则在架构上 DTIM 将系统拆分为三个服务做能力的承载。

**三个服务分别是：**

- *1）*消息服务：负责 IM 核心消息模型和开放 API，IM 基础能力包括消息发送、单聊关系维护、群组元信息管理、历史消息拉取、已读状态通知、IM 数据存储以及跨地域的流量转发；
- *2）*同步服务：负责用户消息数据以及状态数据的端到端同步，通过客户端到服务端长连接通道做实时的数据交互，当钉钉各类设备在线时 IM 及上游各业务通过同步服务做多端的数据同步，保障各端数据和体验一致；
- *3）*通知服务：负责用户第三方通道维护以及通知功能，当钉钉的自建通道无法将数据同步到端上时，通过三方提供的通知和透传能力做消息推送，保障钉钉消息的及时性和有效性。

同步服务和通知服务除了服务于消息服务，也面向其他钉钉业务比如音视频、直播、Ding、文档等多端 (多设备) 数据同步



### 消息服务


DTIM 相对传统 toC 的场景，有较明显的区别：
- 第一是对实时性的要求：在企业服务中，比如员工聊天消息、各种系统报警，又比如音视频中的共享画板，无不要求实时事件同步，因此需要一种低延时的同步方案。
- 第二是弱网接入的能力：在 DTIM 服务的对象中，上千万的企业组织涉及各行各业，从大城市 5G 的高速到偏远的山区弱网，都需要 DTIM 的消息能发送、能触达。对于复杂的网络环境，需要服务端能判断接入环境，并依据不同的环境条件调整同步数据的策略。
- 第三是功耗可控成本可控：在 DTIM 的企业场景中，消息收发频率比传统的 IM 多出一个数量级，在这么大的消息收发场景怎么保障 DTIM 的功耗可控，特别是移动端的功耗可控，是 DTIM 必须面对的问题。在这种要求下，就需要 DTIM 尽量降低 IO 次数，并基于不同的消息优先级进行合并同步，既能要保障实时性不被破坏，又要做到低功耗。

从以上三点可知，服务端主动推送的模型更适合 DTIM 场景：
- 首先可以做到极低的延时，保障推送耗时在毫秒级别；
- 其次是服务端能通过用户接入信息判断用户接入环境好坏，进行对应的分包优化，保障弱网链路下的成功率；
- 最后是主动推送相对于推拉结合来说，可以降低一次 IO，对 DTIM 这种每分钟过亿消息服务来说，能极大的降低设备功耗，同时配合消息优先级合并包的优化，进一步降低端的功耗。

虽说主动推送有诸多优势，但是客户端会离线，甚至客户端处理速度无法跟上服务端的速度，必然导致消息堆积。
DTIM 为了协调服务端和客户端处理能力不一致的问题，支持 Rebase 的能力，当服务端消息堆积的条数达到一定阈值时触发 Rebase，客户端会从 DTIM 拉取最新的消息，同时服务端跳过这部分消息从最新的位点开始推送消息。DTIM 称这个同步模型为推优先模型（Preferentially-Push Model，PPM）。
在基于 PPM 的推送方案下，为了保障消息的可靠达到，DTIM 还做一系列优化
这些优化具体是：
- 支持消息可重入：服务端可能会针对某条消息做重复推送，客户端需要根据 msgId 做去重处理，避免端上消息重复展示。
- 支持消息排序：服务端推送消息特别是群比较活跃的场景，某条消息由于推送链路或者端侧网络抖动，推送失败，而新的消息正常推送到端侧，如果端上不做消息排序的话，消息列表就会发生乱序，所以服务端会为每条消息分配一个时间戳，客户端每次进入消息列表就是根据时间戳做排序再投递给 UI 层做消息展示。
- 支持缺失数据回补：在某个极端情况下客户端群消息事件比群创建事件更早到达端上，此时端上没有群的基本信息消息也就无法展现，所以需要客户端主动向服务端拉取群信息同步到本地，再做消息的透出

### 存储模型

了解 IM 服务最快的途径就是掌握它的存储模型。

业界主流 IM 服务对于消息、会话、会话与消息的组织关系虽然不尽相同，但是归纳起来主要是两种形式：写扩散读聚合、读扩散写聚合。

所谓读写扩散其实是定义消息在群组会话中的存储形式





DTIM 底层使用了表格存储作为消息系统的核心存储系统，表格存储是一个典型 LSM 存储架构，读写放大是此类系统的典型问题。

LSM 系统通过 Major Compaction 来降低数据的 Level 高度，降低读取数据放大的影响。
在 DTIM 的场景中，实时消息写入超过百万 TPS，系统需要划归非常多的计算资源用于 Compaction 处理，但是在线消息读取延迟毛刺依旧严重。

在存储的性能分析中，我们发现如下几个特点：

- 6% 的用户贡献了 50% 左右的消息量，20% 的用户贡献了 74% 的消息量。高频用户产生的消息远多于低频用户，在 Flush MemTable 时，高频用户消息占据了文件的绝大部分；
- 对于高频的用户，由于其“高频”的原因，当消息进入 DTIM，系统发现用户设备在线（高概率在线），会立即推送消息，因此需要推送的消息大部分在内存的 MemTable 中；
- 高频用户产生大量的消息，Compaction 耗费了系统大量的计算和 IO 资源；
- 低频的用户消息通常散落在多个文件当中


从上面的四个表现来看，我们能得出如下结论：
- 绝大部分 Compaction 是无效的计算和 IO，由于大量消息写入产生大量的文件，但是高频的用户消息其实已经下推给用户的设备，Compaction 对读加速效果大打折扣。反而会抢占计算资源，同时引起 IO 抖动；
- 低频用户由于入库消息频率低，在 Flush 之后的文件中占比低；同时用户上线频率低，期间会累计较多的待接收的消息，那么当用户上线时，连续的历史消息高概率散落在多个文件当中，导致遍历读取消息毛刺，严重的有可能读取超时。

为了解决此类问题，我们采用分而治之方法，将高频用户和低频用户的消息区别对待。
我们借鉴了 WiscKey KV 分离技术的思想，就是将到达一定阈值的 Value 分离出来，降低这类消息在文件中的占比进而有效的降低写放大的问题
但是 WiscKey KV 分离仅考虑单 Key 的情况，在 DITM 的场景下，Key 之间的大小差距不大，直接采用这种 KV 分离技术并不能解决以上问题。
因此我们在原有 KV 分离的基础上，改进了 KV 分离，将相同前缀的多个 Key 聚合判断，如果多个 Key 的 Value 超过阈值，那么将这些 Key 的 Value 打包了 value-block 分离出去，写入到 value 文件。
数据显示：上述方法能够在 Minor Compaction 阶段将 MemTable 中 70% 的消息放入 value 文件，大幅降低 key 文件大小，带来更低的写放大；
同时，Major Compaction 可以更快降低 key 文件数，使读放大更低。高频用户发送消息更多，因此其数据行更容易被分离到 value 文件。
读取时，高频用户一般把最近消息全部读出来，考虑到 DTIM 消息 ID 是递增生成，消息读取的 key 是连续的，同一个 value-block 内部的数据会被顺序读取，
基于此，通过 IO 预取技术提前读取 value-block，可以进一步提高性能。对于低频用户，其发送消息较少，K-V 分离不生效，从而减少读取时候 value 文件带来的额外 IO。


### 同步模型







## Links

- [IM](/docs/CS/SE/IM/IM.md)