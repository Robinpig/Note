## Introduction

A hash is a mathematical function that converts an input of arbitrary length into an encrypted output of a fixed length. 
Thus regardless of the original amount of data or file size involved, its unique hash will always be the same size. 
Moreover, hashes cannot be used to "reverse-engineer" the input from the hashed output, since hash functions are "one-way" (like a meat grinder; you can't put the ground beef back into a steak). 
Still, if you use such a function on the same data, its hash will be identical, so you can validate that the data is the same (i.e., unaltered) if you already know its hash.



### Perfect hash function
If all keys are known ahead of time, a [perfect hash function](https://en.wikipedia.org/wiki/Perfect_hash_function) can be used to create a perfect hash table that has no collisions.[9] If minimal perfect hashing is used, every location in the hash table can be used as well.[10]

Perfect hashing allows for constant time lookups in all cases. This is in contrast to most chaining and open addressing methods, where the time for lookup is low on average, but may be very large, O(n), for instance when all the keys hash to a few values.



### Key statistics

A critical statistic for a hash table is the `load factor`, defined as

$$
loadfactor(\alpha)=\frac{n}{k}
$$


where

-  n is the number of entries occupied in the hash table.
-  k is the number of buckets.

The [performance](https://en.wikipedia.org/wiki/Computer_performance) of the hash table worsens in relation to the load factor ({\displaystyle \alpha } i.e. as {\displaystyle \alpha} approaches 1. Hence, it's essential to resize—or "rehash"—the hash table when the load factor exceeds an ideal value. It's also efficient to resize the hash table if the size is smaller—which is usually done when load factor drops below {\displaystyle \alpha _{max}/4}. Generally, a load factor of 0.6 and 0.75 is an acceptable figure.

## Collision resolution

### The cause of the hash conflict
Hashing is a solution to improve efficiency by recompressing data. However, because the hash value generated by the hash function is limited and the data may be more, there are still different data corresponding to the same value after processing by the hash function. This is where you have a hash conflict.
### The influencing factors of hash conflict
Load factor (load factor = total number of data/hash table length), hash function, method of handling conflicts

### Four ways to resolve hash conflicts

- Open Addressing
- Separate Chaining
- rehash
- overflow table

### Separate Chaining

- [HashMap in Java](/docs/CS/Java/JDK/Collection/Map.md?id=hash)
- [Redis hash](/docs/CS/DB/Redis/hash.md)



### Open Addressing

Like separate chaining, open addressing is a method for handling collisions. In Open Addressing, all elements are stored in the hash table itself. So at any point, the size of the table must be greater than or equal to the total number of keys (Note that we can increase table size by copying old data if needed). 

- Insert(k): Keep probing until an empty slot is found. Once an empty slot is found, insert k. 
- Search(k): Keep probing until slot’s key doesn’t become equal to k or an empty slot is reached. 
- Delete(k): ***Delete operation is interesting***. If we simply delete a key, then the search may fail. So slots of deleted keys are marked specially as “deleted”. 
  The insert can insert an item in a deleted slot, but the search doesn’t stop at a deleted slot. 





- [ThreadLocalMap in Java](/docs/CS/Java/JDK/Concurrency/ThreadLocal.md?id=hash)
- HashMap in Python
- [map - Golang](/docs/CS/Go/Basic/map.md)

## Dynamic resizing

### Incremental resizing


- [Redis rehash](/docs/CS/DB/Redis/hash.md?id=rehash)


## References
1. [Hash table - WiKi](https://en.wikipedia.org/wiki/Hash_table)
2. [Hashing | Set 3 (Open Addressing)](https://www.geeksforgeeks.org/hashing-set-3-open-addressing/)
3. [Hashing | Set 2 (Separate Chaining)](https://www.geeksforgeeks.org/hashing-set-2-separate-chaining/)

