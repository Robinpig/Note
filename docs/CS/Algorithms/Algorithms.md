## Introduction

ä¸­æ–‡çš„â€œç®—æ³•â€ä¸€è¯è‡³å°‘åœ¨å”ä»£å°±å‡ºç°äº†ï¼Œåœ¨æ­¤ä¹‹å‰ä¹Ÿæœ‰â€œæœ¯â€â€œç®—æœ¯â€ç­‰è¯ï¼Œæœ€æ—©å‡ºç°åœ¨ã€Šå‘¨é«€ç®—ç»ã€‹ã€Šä¹ç« ç®—æœ¯ã€‹ã€‚è€Œä¸”ï¼Œâ€œç®—æ³•â€ä¸€è¯çš„å«ä¹‰ä»å¤åˆ°ä»Šå‡ ä¹æ²¡æœ‰å‘ç”Ÿå˜åŒ–ã€‚

è‹±æ–‡çš„â€œç®—æ³•â€ï¼ˆalgorithmï¼‰ä¸€è¯æ¥æºäº 9 ä¸–çºªæ³¢æ–¯æ•°å­¦å®¶èŠ±æ‹‰å­ç±³ï¼ˆal-KhwÄrizmÄ«ï¼Œ780?~850?ï¼‰â€”â€”å°±æ˜¯é‚£ä¸ªè§£å†³ä¸€æ¬¡æ–¹ç¨‹åŠä¸€å…ƒäºŒæ¬¡æ–¹ç¨‹çš„æ–¹æ³•çš„äººã€‚èŠ±æ‹‰å­ç±³çš„æ‹‰ä¸æ–‡è¯‘åæ˜¯â€œAlgoritmiâ€ã€‚è‹±æ–‡å¯¹â€œç®—æ³•â€åŸè¯‘ä¸ºâ€œalgorismâ€ï¼Œæ„æ€æ˜¯èŠ±æ‹‰å­ç±³çš„è¿ç®—æ³•åˆ™ï¼Œåœ¨ 18 ä¸–çºªæ¼”å˜ä¸ºâ€œalgorithmâ€ã€‚è¿™ä¸ªè¯å‡ºç°äº 12 ä¸–çºªï¼ŒæŒ‡çš„æ˜¯ç”¨é˜¿æ‹‰ä¼¯æ•°å­—è¿›è¡Œç®—æœ¯è¿ç®—çš„è¿‡ç¨‹

çº¦å…¬å…ƒå‰ 300 å¹´è®°è½½äºã€Šå‡ ä½•åŸæœ¬ã€‹ä¸­çš„è¾—è½¬ç›¸é™¤æ³•ï¼ˆæ¬§å‡ é‡Œå¾—ç®—æ³•ï¼‰è¢«äººä»¬è®¤ä¸ºæ˜¯å²ä¸Šç¬¬ä¸€ä¸ªç®—æ³•ï¼Œå¯ä»¥æ±‚ä¸¤æ•°çš„æœ€å¤§å…¬çº¦æ•°

1936å¹´ å›¾çµæå‡ºã€Šè®ºæ•°å­¦è®¡ç®—åœ¨å†³æ–­éš¾é¢˜ä¸­ä¹‹åº”ç”¨ã€‹ æå‡ºå›¾çµæœºçš„æ¦‚å¿µ 
å›¾çµæœºçš„å‡ºç°è§£å†³äº†ç®—æ³•å®šä¹‰çš„éš¾é¢˜ï¼Œå›¾çµçš„æ€æƒ³å¯¹ç®—æ³•çš„å‘å±•èµ·åˆ°äº†é‡è¦çš„ä½œç”¨

åœ¨æ­¤ä¹‹åï¼Œç®—æ³•æ›´åå‘äºè®¡ç®—æœºç§‘å­¦é¢†åŸŸï¼Œå„ç§è§£å†³ä¸åŒé—®é¢˜çš„ç®—æ³•ä¹Ÿå±‚å‡ºä¸ç©·ï¼Œæ¶‰åŠæ’åºã€ç»Ÿè®¡ã€çº¿æ€§è§„åˆ’ã€æœç´¢ã€å‹ç¼©ç­‰æ–¹é¢ã€‚

åˆ°äº†ç°åœ¨ï¼Œéšç€äººå·¥æ™ºèƒ½å’Œæœºå™¨å­¦ä¹ çš„å‘å±•ï¼Œæ¶‰åŠåˆ°ç¥ç»ç½‘ç»œçš„ç®—æ³•å˜å¾—è¶Šå‘é‡è¦





## Data Structures

æ•°æ®ç»“æ„æ˜¯åœ¨è®¡ç®—æœºä¸­å­˜å‚¨å’Œç»„ç»‡æ•°æ®çš„ä¸€ç§ç‰¹å®šæ–¹å¼ï¼Œä»¥ä¾¿èƒ½å¤Ÿé«˜æ•ˆåœ°ä½¿ç”¨è¿™äº›æ•°æ®
å¸¸è§çš„æ•°æ®ç»“æ„ç±»å‹åŒ…æ‹¬æ•°ç»„ã€é“¾è¡¨ã€æ ˆã€é˜Ÿåˆ—ã€æ ‘ã€å›¾ç­‰ã€‚

æ ¹æ®å…ƒç´ çš„ç»„ç»‡æ–¹å¼ï¼Œæ•°æ®ç»“æ„å¯åˆ†ä¸ºä¸¤ç±»

1) çº¿æ€§æ•°æ®ç»“æ„ï¼šå…ƒç´ æŒ‰é¡ºåºè®¿é—®ï¼Œä½†ä¸å¿…å°†æ‰€æœ‰å…ƒç´ é¡ºåºå­˜å‚¨ ä¾‹å¦‚ï¼šé“¾è¡¨ã€æ ˆå’Œé˜Ÿåˆ—
2) éçº¿æ€§æ•°æ®ç»“æ„ï¼šæ­¤æ•°æ®ç»“æ„çš„å…ƒç´ ä»¥éçº¿æ€§é¡ºåºå­˜å‚¨/è®¿é—® ä¾‹å¦‚ï¼šæ ‘å’Œå›¾

An *abstract data type* (**ADT**) is a set of operations.
Abstract data types are mathematical abstractions; nowhere in an ADT's definition is there any mention of how the set of operations is implemented.
This can be viewed as an extension of modular design.

Commonly used ADTs include: Linked Lists, Stacks, Queues, Priority Queues, Binary Trees, Dictionaries, Disjoint Sets (Union and Find), Hash Tables, Graphs, and many others.
For example, stack uses a LIFO (Last-In-First-Out) mechanism while storing the data in data structures.
The last element inserted into the stack is the first element that gets deleted.
Common operations are: creating the stack, pushing an element onto the stack, popping an element from the stack, finding the current top of the stack, finding the number of elements in the stack, etc.

While defining the ADTs do not worry about the implementation details.
They come into the picture only when we want to use them.
Different kinds of ADTs are suited to different kinds of applications, and some are highly specialized to specific tasks.
We will go through many of them and you will be in a position to relate the data structures to the kind of problems they solve.

### Lists, Stacks, and Queues

[Lists](/docs/CS/Algorithms/struct/list.md), [stacks](/docs/CS/Algorithms/struct/stack.md), and [queues](/docs/CS/Algorithms/struct/queue.md) are perhaps the three fundamental data structures in all of computer science.

[Arrays and Linked Lists](/docs/CS/Algorithms/struct/linked-list.md)


We introduce [hash tables](/docs/CS/Algorithms/hash.md), a widely used data structure supporting the dictionary operations INSERT, DELETE, and SEARCH.
In the worst case, hash tables require Î˜(n) time to perform a SEARCH operation, but the expected time for hash-table operations is $O(1)$.
We rely on probability to analyze hash-table operations, but you can understand how the operations work even without probability.

### Tree

[Trees](/docs/CS/Algorithms/tree/tree.md) in general are very useful abstractions in computer science.

- [Trie](/docs/CS/Algorithms/tree/Trie.md)
- [Red-Black Tree](/docs/CS/Algorithms/tree/Red-Black-Tree.md)

> [!NOTE]
>
> **Definition**.
> A symbol table is a data structure for key-value pairs that supports two operations: insert (put) a new pair into the table and search for (get) the value associated with a given key.

### Heap

[heaps](/docs/CS/Algorithms/struct/heap.md)

### Graph

[Graph](/docs/CS/Algorithms/graph/graph.md)



[Disjoing Set](/docs/CS/Algorithms/Disjoint-Ser.md)

[BloomFilter](/docs/CS/Algorithms/struct/BloomFilter.md)





### Page Replacement Algorithms

- [LRU](/docs/CS/Algorithms/LRU.md)


| ç®—æ³•è§„åˆ™                | ä¼˜ç¼ºç‚¹                                                                                                                                                                           |
| ------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OPT                     | ä¼˜å…ˆæ·˜æ±°æœ€é•¿æ—¶é—´å†…ä¸ä¼šè¢«è®¿é—®çš„é¡µé¢	ç¼ºé¡µç‡æœ€å°ï¼Œæ€§èƒ½æœ€å¥½;ä½†æ— æ³•å®ç°                                                                                                               |
| FIFO                    | ä¼˜å…ˆæ·˜æ±°æœ€å…ˆè¿›å…¥å†…å­˜çš„é¡µé¢	å®ç°ç®€å•;ä½†æ€§èƒ½å¾ˆå·®ï¼Œå¯èƒ½å‡ºç°Beladyå¼‚å¸¸                                                                                                               |
| LRU                     | ä¼˜å…ˆæ·˜æ±°æœ€è¿‘æœ€ä¹…æ²¡è®¿é—®çš„é¡µé¢	æ€§èƒ½å¾ˆå¥½;ä½†éœ€è¦ç¡¬ä»¶æ”¯æŒï¼Œç®—æ³•å¼€é”€å¤§                                                                                                                 |
| CLOCK (NRU)             | å¾ªç¯æ‰«æå„é¡µé¢ ç¬¬ä¸€è½®æ·˜æ±°è®¿é—®ä½=0çš„ï¼Œå¹¶å°†æ‰«æè¿‡çš„é¡µé¢è®¿é—®ä½æ”¹ä¸º1ã€‚è‹¥ç¬¬-è½®æ²¡é€‰ä¸­ï¼Œåˆ™è¿›è¡Œç¬¬äºŒè½®æ‰«æã€‚	å®ç°ç®€å•ï¼Œç®—æ³•å¼€é”€å°;ä½†æœªè€ƒè™‘é¡µé¢æ˜¯å¦è¢«ä¿®æ”¹è¿‡ã€‚                              |
| æ”¹è¿›å‹CLOCK (æ”¹è¿›å‹NRU) | è‹¥ç”¨(è®¿é—®ä½ï¼Œä¿®æ”¹ä½)çš„å½¢å¼è¡¨è¿°ï¼Œåˆ™ ç¬¬ä¸€è½®:æ·˜æ±°(0,0) ç¬¬äºŒè½®:æ·˜æ±°(O,1)ï¼Œå¹¶å°†æ‰«æè¿‡çš„é¡µé¢è®¿é—®ä½éƒ½ç½®ä¸º0 ç¬¬ä¸‰è½®:æ·˜æ±°(O, 0) ç¬¬å››è½®:æ·˜æ±°(0, 1)	ç®—æ³•å¼€é”€è¾ƒå°ï¼Œæ€§èƒ½ä¹Ÿä¸é”™ PDFæ–‡æ¡£ä¸‹è½½æ–¹å¼ |

## Algorithm Analysis

An *algorithm* is a finite set of instructions that, if followed, accomplishes a particular task.
In addition, all algorithms must satisfy the following criteria:

1. **Input**. There are zero or more quantities that are externally supplied.
2. **Output**. At least one quantity is produced.
3. **Definiteness**. Each instruction is clear and unambiguous.
4. **Finiteness**. If we trace out the instructions of an algorithm, then for all cases, the algorithm terminates after a finite number of steps.
5. **Effectiveness**. Every instruction must be basic enough to be carried out, in principle, by a person using only pencil and paper. 
   It is not enough that each operation be definite as in 3; it also must be feasible.

Computer algorithms solve computational problems.
We want two things from a computer algorithm: given an input to a problem, it should always produce a correct solution to the problem, and it should use computational resources efficiently while doing so. 
Letâ€™s examine these two desiderata in turn.

For some problems, it might be difficult or even impossible to say whether an algorithm produces a correct solution.
Sometimes we can accept that a computer algorithm might produce an incorrect answer, as long as we can control how often it does so.
Correctness is a tricky issue with another class of algorithms, called *approximation algorithms*. 
Approximation algorithms apply to optimization problems, in which we want to find the best solution according to some quantitative measure.
Finding the fastest route, as a GPS does, is one example, where the quantitative measure is travel time.
For some problems, we have no algorithm that finds an optimal solution in any reasonable amount of time, but we know of an approximation algorithm that,
in a reasonable amount of time, can find a solution that is almost optimal. 

**What does it mean for an algorithm to use computational resources efficiently?** 

Indeed, time is the primary measure of efficiency that we use to evaluate an algorithm, once we have shown that the algorithm gives a correct solution.
But it is not the only measure.
We might be concerned with how much computer memory the algorithm requires (its â€œmemory footprintâ€), since an algorithm has to run within the available memory.
Other possible resources that an algorithm might use: network communication, random bits (because algorithms that make random choices need a source of random numbers),
or disk operations (for algorithms that are designed to work with disk-resident data).â€



### Complexity

Algorithms can be evaluated by a variety of criteria.
Most often we shall be interested in the rate of growth of the time or space required to solve larger and larger instances of a problem.
We would like to associate with a problem an integer. called the size of the problem, which is a measure of the quantity of input data.

The time needed by an algorithm expressed as a function of the size of a problem is called the *time complexity* of the algorithm.
The limiting behavior of the compiexity as size increases is called the *asymptotic time complexity*.
Analogous definitions can be made for *space complexity* and *asymptotic space complexity*.

The asymptotic complexity of an algorithm is an important measure of the goodness of an algorithm, one that promises to become even more important with future increases in computing speed.

Despite our concentration on order-of-magnitude performance, we should realize that an algorithm with a rapid growth rate might have a smaller constant of proportionality than one with a lower growth rate.
In that case. the rapidly growing algorithm might be superior for small problems. possibly even for all problems of a size that would interest us.

If for a given size the complexity is taken as the maximum complexity over all inputs of that size, then the complexity is called the *worst-case complexity*.
If the complexity is taken as the "average" complexity over all inputs of given size. then the complexity is called the *expected complexity*.
The expected complexity of an algorithm is usually more difficult to ascertain than the worst-case complexity.
One must make some assumption about the distribution of inputs, and realistic assumptions are often not mathematically tractable.
We shall emphasize the worst case, since it is more tractable and has a universal applicability.
However. it should be borne in mind that the algorithm with the best worst-case complexity does not necessarily have the best expected complexity.

In theoretical analysis of algorithms it is common to estimate their complexity in the asymptotic sense, i.e., to estimate the complexity function for arbitrarily large input.
Big O notation, Big-omega notation and Big-theta notation are used to this end.


O-notation characterizes an upper bound on the asymptotic behavior of a function.
In other words, it says that a function grows no faster than a certain rate, based on the highest-order term.


> Knuth traces the origin of the O-notation to a number-theory text by P. Bachmann in 1892.
> The o-notation was invented b y E. Landau in b 1909 for his discussion of the distribution of prime numbers.
> The Î© and Î˜ notations were advocated bay Knuth to correct the popular, but technically sloppy, practice in the literature of using O-notation for both upper and lower bounds.

An abstract data type (ADT) is a data type that is organized in such a way that the specification of the objects and the specification of the operations on the objects is separated from the representation of the objects and the implementation of the operations.

> An algorithm is efficient if its running time is polynomial.



å‡æ‘Šæ—¶é—´å¤æ‚åº¦ï¼Œå¬èµ·æ¥è·Ÿå¹³å‡æ—¶é—´å¤æ‚åº¦æœ‰ç‚¹å„¿åƒã€‚å¯¹äºåˆå­¦è€…æ¥è¯´ï¼Œè¿™ä¸¤ä¸ªæ¦‚å¿µç¡®å®éå¸¸å®¹æ˜“å¼„æ··ã€‚æˆ‘å‰é¢è¯´äº†ï¼Œå¤§éƒ¨åˆ†æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¹¶ä¸éœ€è¦åŒºåˆ†æœ€å¥½ã€æœ€åã€å¹³å‡ä¸‰ç§å¤æ‚åº¦ã€‚å¹³å‡å¤æ‚åº¦åªåœ¨æŸäº›ç‰¹æ®Šæƒ…å†µä¸‹æ‰ä¼šç”¨åˆ°ï¼Œè€Œå‡æ‘Šæ—¶é—´å¤æ‚åº¦åº”ç”¨çš„åœºæ™¯æ¯”å®ƒæ›´åŠ ç‰¹æ®Šã€æ›´åŠ æœ‰é™



### Computation Model

Exact (not asymptotic) measures of efficiency can sometimes be computed but they usually require certain assumptions concerning the particular implementation of the algorithm, called model of computation.
A model of computation may be defined in terms of an abstract computer, e.g., Turing machine, and/or by postulating that certain operations are executed in unit time.

This model clearly has some weaknesses. Obviously, in real life, not all operations take exactly the same time.
In particular, in our model one disk read counts the same as an addition, even though the addition is typically several orders of magnitude faster.
Also, by assuming infinite memory, we never worry about page faulting, which can be a real



### Algorithm Types

å°†ç®—æ³•ä»é—®é¢˜åˆ°æ•°æ®ç»´åº¦ä¸Šå½’ç±» å¯ä»¥é€šè¿‡ ä½“ç§¯(Volumn)ã€é€Ÿåº¦(Velocity) å’Œ å¤šæ ·æ€§(Variety)





Euclid's algorithm is for computing the greatest common divisor.
The greatest common divisor (gcd) of two integers is the largest integer that divides both.



**æšä¸¾ç®—æ³•ï¼ˆEnumeration Algorithmï¼‰**ï¼Œåˆç§°ç©·ä¸¾ç®—æ³•ï¼Œæ˜¯æŒ‡æ ¹æ®é—®é¢˜çš„ç‰¹ç‚¹ï¼Œé€ä¸€åˆ—å‡ºæ‰€æœ‰å¯èƒ½çš„è§£ï¼Œå¹¶ä¸ç›®æ ‡æ¡ä»¶è¿›è¡Œæ¯”è¾ƒï¼Œæ‰¾å‡ºæ»¡è¶³è¦æ±‚çš„ç­”æ¡ˆã€‚æšä¸¾æ—¶è¦ç¡®ä¿ä¸é—æ¼ã€ä¸é‡å¤
ç”±äºéœ€è¦éå†æ‰€æœ‰çŠ¶æ€ï¼Œæšä¸¾ç®—æ³•åœ¨é—®é¢˜è§„æ¨¡è¾ƒå¤§æ—¶æ•ˆç‡è¾ƒä½
å› æ­¤ï¼Œæšä¸¾ç®—æ³•å¸¸ç”¨äºå°è§„æ¨¡é—®é¢˜ï¼Œæˆ–ä½œä¸ºå…¶ä»–ç®—æ³•çš„è¾…åŠ©å·¥å…·ï¼Œé€šè¿‡æšä¸¾éƒ¨åˆ†ä¿¡æ¯æ¥æå‡ä¸»ç®—æ³•çš„æ•ˆç‡

æšä¸¾ç®—æ³•çš„åº”ç”¨

ä¸¤æ•°ä¹‹å’Œ



### Advanced Design and Analysis Techniques

Text-editing programs frequently need to find all occurrences of a pattern in the text.
Typically, the text is a document being edited, and the pattern searched for is a particular word supplied by the user.
Efficient algorithms for this problemâ€”called â€œ[string matching](/docs/CS/Algorithms/string-search)â€â€”can greatly aid the responsiveness of the text-editing program.

- [Dynamic Programming](/docs/CS/Algorithms/DP/DP.md)
- [Greedy Programming](/docs/CS/Algorithms/Greedy.md)
- [Amortized Analysis](/docs/CS/Algorithms/Amortized.md)
- [Randomized](/docs/CS/Algorithms/Randomized.md)
- [Backtracking](/docs/CS/Algorithms/Backtracking.md)
- [Divide and Conquer](/docs/CS/Algorithms/Divide-and-Conquer.md)


å¸¸è§çš„ç®—æ³•ä¼˜åŒ–æŠ€å·§

[åŒæŒ‡é’ˆ](/docs/CS/Algorithms/Two-Pointers.md)

å‰ç¼€å’Œä¸å·®åˆ†æ˜¯ç®—æ³•ç«èµ›ä¸­å¸¸ç”¨çš„æŠ€å·§ï¼Œå‰è€…ç”¨äºå¿«é€Ÿæ±‚åŒºé—´å’Œï¼Œåè€…ç”¨äºé«˜æ•ˆè¿›è¡ŒåŒºé—´ä¿®æ”¹


å‰ç¼€å’Œå¯ä»¥ç®€å•ç†è§£ä¸ºã€Œæ•°åˆ—çš„å‰ n é¡¹çš„å’Œã€ï¼Œæ˜¯ä¸€ç§é‡è¦çš„é¢„å¤„ç†æ–¹å¼
å¯¹äºé•¿åº¦ä¸º n çš„åºåˆ— \{a_i\}ï¼Œå¦‚æœè¦å¤šæ¬¡æŸ¥è¯¢åŒºé—´ [l,r] ä¸­åºåˆ—æ•°å­—çš„å’Œï¼Œå°±å¯ä»¥è€ƒè™‘ä½¿ç”¨å‰ç¼€å’Œï¼åºåˆ—çš„å‰ç¼€å’Œå°±æ˜¯


ğ‘†ğ‘–=
ğ‘–
âˆ‘
ğ‘—=1

ğ‘ğ‘—.

è¦è¯¢é—®åŒºé—´ [ğ‘™,ğ‘Ÿ]
[l,r] å†…çš„åºåˆ—çš„å’Œï¼Œåªéœ€è¦è®¡ç®—å·®å€¼

ğ‘†([ğ‘™,ğ‘Ÿ])=ğ‘†ğ‘Ÿâˆ’ğ‘†ğ‘™âˆ’1.

å°±è¿™æ ·ï¼Œé€šè¿‡ ğ‘‚(ğ‘›)
O(n) æ—¶é—´é¢„å¤„ç†ï¼Œèƒ½å¤Ÿå°†å•æ¬¡æŸ¥è¯¢åŒºé—´å’Œçš„å¤æ‚åº¦é™ä½åˆ° ğ‘‚(1)
O(1)


å·®åˆ†æ˜¯ä¸€ç§ä¸å‰ç¼€å’Œç›¸å¯¹çš„ç­–ç•¥ï¼Œæ˜¯å‰ç¼€å’Œçš„é€†è¿ç®—ï¼ç›¸è¾ƒäºç»™å®šæŸä¸€åºåˆ—æ±‚å®ƒçš„å·®åˆ†ï¼Œç«èµ›ä¸­æ›´ä¸ºå¸¸è§çš„æƒ…æ™¯æ˜¯ï¼Œé€šè¿‡ç»´æŠ¤å·®åˆ†åºåˆ—çš„ä¿¡æ¯ï¼Œå®ç°å¤šæ¬¡åŒºé—´ä¿®æ”¹ï¼åœ¨åŒºé—´ä¿®æ”¹ç»“æŸåï¼Œå¯ä»¥é€šè¿‡å‰ç¼€å’Œæ¢å¤åŸåºåˆ—çš„ä¿¡æ¯ï¼Œå®ç°å¯¹åŸåºåˆ—çš„æŸ¥è¯¢ï¼æ³¨æ„ä¿®æ”¹æ“ä½œä¸€å®šè¦åœ¨æŸ¥è¯¢æ“ä½œä¹‹å‰



### Sorting and Order Statistics

- [Sort](/docs/CS/Algorithms/sort.md)


### Pattern Matching

[Pattern search algorithms](/docs/CS/Algorithms/string/string-search.md) are essential tools in computer science and data processing.
These algorithms are designed ti efficiently find a particular pattern within a larger set of data.

### Consensus Algorithm

Paxos

Raft

### Compression Algorithms

### 

Galeâ€“Shapley algorithm (also known as the Deferred Acceptance algorithm).
Gale Shapley Algorithm is an efficient algorithm that is used to solve the Stable Matching problem. 
It takes $O(N^2)$ time complexity where N is the number of people involved.

The subject called the [â€œNP-completeâ€ problems](/docs/CS/Algorithms/NP.md), whose status is unknown.
No polynomial-time algorithm has yet been discovered for an NP-complete problem, nor has anyone yet been able to prove that no polynomial-time algorithm can exist for any one of them.
This so-called $P != NP$ question has been one of the deepest, most perplexing open research problems in theoretical computer science since it was first posed in 1971.



## Practice


LeetCode

Online Judge

- [æ´›è°·](https://luogu.com.cn)
- [LibreOJ](https://loj.ac)
- [ZOJ](https://acm.zju.edu.cn/)
- [POJ](https://poj.org)
- [HDU](https://acm.hdu.edu.cn)
- [Codeforces](https://codeforces.com)

## Links

- [Computer Organization](/docs/CS/CO/CO.md)
- [Operating Systems](/docs/CS/OS/OS.md)
- [Computer Network](/docs/CS/CN/CN.md)

## References

1. Algorithms + Data Structures = Programs
2. Introduction to Algorithms Third Edition
2. Introduction to The Design and Analysis of Algorithms Third Edition
3. Algorithms Fourth Edition
4. Data Structures and Algorithm Analysis in C
5. The Design and Analysis of Computer Algorithms
