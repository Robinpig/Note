## Introduction



### compile_java_method

[CompilerThread](/docs/CS/Java/JDK/JVM/Thread.md?id=CompilerThread) -> Compilation::compile_method -> Compilation::compile_java_method

1. build hir
2. build lir
3. generate emit_code

```cpp
int Compilation::compile_java_method() {
  if (BailoutOnExceptionHandlers) {
    if (method()->has_exception_handlers()) {
      bailout("linear scan can't handle exception handlers");
    }
  }

  CHECK_BAILOUT_(no_frame_size);

  if (is_profiling() && !method()->ensure_method_data()) {
    BAILOUT_("mdo allocation failed", no_frame_size);
  }

  {
    PhaseTraceTime timeit(_t_buildIR);
    build_hir();
  }
  if (BailoutAfterHIR) {
    BAILOUT_("Bailing out because of -XX:+BailoutAfterHIR", no_frame_size);
  }


  {
    PhaseTraceTime timeit(_t_emit_lir);

    _frame_map = new FrameMap(method(), hir()->number_of_locks(), MAX2(4, hir()->max_stack()));
    emit_lir();
  }
  CHECK_BAILOUT_(no_frame_size);

  // Dump compilation data to replay it.
  if (_directive->DumpReplayOption) {
    env()->dump_replay_data(env()->compile_id());
  }

  {
    PhaseTraceTime timeit(_t_codeemit);
    return emit_code_body();
  }
}
```

更详细的流程如下

```cpp
typedef enum {
  _t_compile,
    _t_setup,
    _t_buildIR,
      _t_hir_parse,
      _t_gvn,
      _t_optimize_blocks,
      _t_optimize_null_checks,
      _t_rangeCheckElimination,
    _t_emit_lir,
      _t_linearScan,
      _t_lirGeneration,
    _t_codeemit,
    _t_codeinstall,
  max_phase_timers
} TimerName;
```

## 

当要对方法代码进行跟踪调试时，使用如下命令：

```
-cp .:/projectjava/bin  \
-Xcomp \
-XX:+TraceLivenessGen \
-XX:TieredStopAtLevel=1 \
-XX:CompileCommand=compileonly,*CompilationDemo.fact com.test/CompilationDemo
```

注意，为了方便查看，对命令行进行了换行，在实际运行过程中，需要变为一行。

-cp可以以参数的方式指定，也可以配置CLASSPATH环境变量；-Xcomp选项也是必不可少的，只有在指定了编译情况下，然后强制使用第一层级的分层编译后，才会使用C1编译器进行编译；-XX:CompileCommand选项指定了只强制编译CompilationDemo.fact()方法







## hir



build_hir()函数解释字节码生成HIR，然后进行一系列的优化动作，如条件表达式消除、基本块消除、全局值编号（GVN，Global Value Numbering）、数组范围检查（Range Check Elimination）和NULL检查消除

```cpp
void Compilation::build_hir() {
  CHECK_BAILOUT();

  // setup ir
  CompileLog* log = this->log();
  if (log != nullptr) {
    log->begin_head("parse method='%d' ",
                    log->identify(_method));
    log->stamp();
    log->end_head();
  }
  {
    PhaseTraceTime timeit(_t_hir_parse);
    _hir = new IR(this, method(), osr_bci());
  }
  if (log)  log->done("parse");
  if (!_hir->is_valid()) {
    bailout("invalid parsing");
    return;
  }

  _hir->verify();

  if (UseC1Optimizations) {
    NEEDS_CLEANUP
    // optimization
    PhaseTraceTime timeit(_t_optimize_blocks);

    _hir->optimize_blocks();
  }

  _hir->verify();

  _hir->split_critical_edges();
  _hir->verify();

  // compute block ordering for code generation
  // the control flow must not be changed from here on
  _hir->compute_code();

  if (UseGlobalValueNumbering) {
    // No resource mark here! LoopInvariantCodeMotion can allocate ValueStack objects.
    PhaseTraceTime timeit(_t_gvn);
    int instructions = Instruction::number_of_instructions();
    GlobalValueNumbering gvn(_hir);
    assert(instructions == Instruction::number_of_instructions(),
           "shouldn't have created an instructions");
  }

  _hir->verify();

  if (RangeCheckElimination) {
    if (_hir->osr_entry() == nullptr) {
      PhaseTraceTime timeit(_t_rangeCheckElimination);
      RangeCheckElimination::eliminate(_hir);
    }
  }

  if (UseC1Optimizations) {
    // loop invariant code motion reorders instructions and range
    // check elimination adds new instructions so do null check
    // elimination after.
    NEEDS_CLEANUP
    // optimization
    PhaseTraceTime timeit(_t_optimize_null_checks);

    _hir->eliminate_null_checks();
  }

  _hir->verify();

  // compute use counts after global value numbering
  _hir->compute_use_counts();

  _hir->verify();
}
```

Compilation::build_graph()函数创建由基本块组成的控制流图，此函数会间接调用到IRScope::build_graph()函数



```cpp
BlockBegin* IRScope::build_graph(Compilation* compilation, int osr_bci) {
  GraphBuilder gm(compilation, this);
  NOT_PRODUCT(if (PrintValueNumbering && Verbose) gm.print_stats());
  if (compilation->bailed_out()) return nullptr;
  return gm.start();
}
```

在创建GraphBuilder类的实例时会调用GraphBuilder类的构造函数



```cpp

GraphBuilder::GraphBuilder(Compilation* compilation, IRScope* scope)
  : _scope_data(nullptr)
  , _compilation(compilation)
  , _memory(new MemoryBuffer())
  , _inline_bailout_msg(nullptr)
  , _instruction_count(0)
  , _osr_entry(nullptr)
{
  int osr_bci = compilation->osr_bci();

  // determine entry points and bci2block mapping
  BlockListBuilder blm(compilation, scope, osr_bci);
  // ...
}

```

在创建BlockListBuilder实例时会调用BlockListBuilder构造函数



```cpp
BlockListBuilder::BlockListBuilder(Compilation* compilation, IRScope* scope, int osr_bci)
 : _compilation(compilation)
 , _scope(scope)
 , _blocks(16)
 , _bci2block(new BlockList(scope->method()->code_size(), nullptr))
 , _bci2block_successors(scope->method()->code_size())
 , _active()         // size not known yet
 , _visited()        // size not known yet
 , _loop_map() // size not known yet
 , _next_loop_index(0)
 , _next_block_number(0)
 , _block_id_start(0)
{
  set_entries(osr_bci);
  set_leaders();
  CHECK_BAILOUT();

  mark_loops();
  NOT_PRODUCT(if (PrintInitialBlockList) print());

  // _bci2block still contains blocks with _end == null and > 0 sux in _bci2block_successors.
}
```
### set_entries
```cpp
void BlockListBuilder::set_entries(int osr_bci) {
  // generate start blocks
  BlockBegin* std_entry = make_block_at(0, nullptr);
  if (scope()->caller() == nullptr) {
    std_entry->set(BlockBegin::std_entry_flag);
  }
  if (osr_bci != -1) {
    BlockBegin* osr_entry = make_block_at(osr_bci, nullptr);
    osr_entry->set(BlockBegin::osr_entry_flag);
  }

  // generate exception entry blocks
  XHandlers* list = xhandlers();
  const int n = list->length();
  for (int i = 0; i < n; i++) {
    XHandler* h = list->handler_at(i);
    BlockBegin* entry = make_block_at(h->handler_bci(), nullptr);
    entry->set(BlockBegin::exception_entry_flag);
    h->set_entry_block(entry);
  }
}
```





```cpp
BlockBegin* BlockListBuilder::make_block_at(int cur_bci, BlockBegin* predecessor) {
  assert(method()->bci_block_start().at(cur_bci), "wrong block starts of MethodLivenessAnalyzer");

  BlockBegin* block = _bci2block->at(cur_bci);
  if (block == nullptr) {
    block = new BlockBegin(cur_bci);
    block->init_stores_to_locals(method()->max_locals());
    _bci2block->at_put(cur_bci, block);
    _bci2block_successors.at_put_grow(cur_bci, BlockList());
    _blocks.append(block);

    assert(predecessor == nullptr || predecessor->bci() < cur_bci, "targets for backward branches must already exist");
  }

  if (predecessor != nullptr) {
    if (block->is_set(BlockBegin::exception_entry_flag)) {
      BAILOUT_("Exception handler can be reached by both normal and exceptional control flow", block);
    }

    add_successor(predecessor, block);
    block->increment_total_preds();
  }

  return block;
}
```

通过_bci2block判断是否已经为当前的字节码指令建立了基本块，如果没有建立基本块，需要创建BlockBegin并添加到_blocks属性中保存。同时也更新_bci2block属性，这个属性能让我们在知道字节码下标索引的情况下，找到这个字节码所在的基本块，另外还能避免重复创建基本块，例如在回边的时候，跳转的目标字节码指令可能已经有了对应的基本块，我们不需要再重新创建了

### set_leaders

```cpp
void BlockListBuilder::set_leaders() {
  bool has_xhandlers = xhandlers()->has_handlers();
  BlockBegin* current = nullptr;

  // The information which bci starts a new block simplifies the analysis
  // Without it, backward branches could jump to a bci where no block was created
  // during bytecode iteration. This would require the creation of a new block at the
  // branch target and a modification of the successor lists.
  const BitMap& bci_block_start = method()->bci_block_start();

  int end_bci = method()->code_size();

  ciBytecodeStream s(method());
  while (s.next() != ciBytecodeStream::EOBC()) {
    int cur_bci = s.cur_bci();

    if (bci_block_start.at(cur_bci)) {
      current = make_block_at(cur_bci, current);
    }
    assert(current != nullptr, "must have current block");

    if (has_xhandlers && GraphBuilder::can_trap(method(), s.cur_bc())) {
      handle_exceptions(current, cur_bci);
    }

    switch (s.cur_bc()) {
      // track stores to local variables for selective creation of phi functions
      case Bytecodes::_iinc:     store_one(current, s.get_index()); break;
      case Bytecodes::_istore:   store_one(current, s.get_index()); break;
      case Bytecodes::_lstore:   store_two(current, s.get_index()); break;
      case Bytecodes::_fstore:   store_one(current, s.get_index()); break;
      case Bytecodes::_dstore:   store_two(current, s.get_index()); break;
      case Bytecodes::_astore:   store_one(current, s.get_index()); break;
      case Bytecodes::_istore_0: store_one(current, 0); break;
      case Bytecodes::_istore_1: store_one(current, 1); break;
      case Bytecodes::_istore_2: store_one(current, 2); break;
      case Bytecodes::_istore_3: store_one(current, 3); break;
      case Bytecodes::_lstore_0: store_two(current, 0); break;
      case Bytecodes::_lstore_1: store_two(current, 1); break;
      case Bytecodes::_lstore_2: store_two(current, 2); break;
      case Bytecodes::_lstore_3: store_two(current, 3); break;
      case Bytecodes::_fstore_0: store_one(current, 0); break;
      case Bytecodes::_fstore_1: store_one(current, 1); break;
      case Bytecodes::_fstore_2: store_one(current, 2); break;
      case Bytecodes::_fstore_3: store_one(current, 3); break;
      case Bytecodes::_dstore_0: store_two(current, 0); break;
      case Bytecodes::_dstore_1: store_two(current, 1); break;
      case Bytecodes::_dstore_2: store_two(current, 2); break;
      case Bytecodes::_dstore_3: store_two(current, 3); break;
      case Bytecodes::_astore_0: store_one(current, 0); break;
      case Bytecodes::_astore_1: store_one(current, 1); break;
      case Bytecodes::_astore_2: store_one(current, 2); break;
      case Bytecodes::_astore_3: store_one(current, 3); break;

      // track bytecodes that affect the control flow
      case Bytecodes::_athrow:  // fall through
      case Bytecodes::_ret:     // fall through
      case Bytecodes::_ireturn: // fall through
      case Bytecodes::_lreturn: // fall through
      case Bytecodes::_freturn: // fall through
      case Bytecodes::_dreturn: // fall through
      case Bytecodes::_areturn: // fall through
      case Bytecodes::_return:
        current = nullptr;
        break;

      case Bytecodes::_ifeq:      // fall through
      case Bytecodes::_ifne:      // fall through
      case Bytecodes::_iflt:      // fall through
      case Bytecodes::_ifge:      // fall through
      case Bytecodes::_ifgt:      // fall through
      case Bytecodes::_ifle:      // fall through
      case Bytecodes::_if_icmpeq: // fall through
      case Bytecodes::_if_icmpne: // fall through
      case Bytecodes::_if_icmplt: // fall through
      case Bytecodes::_if_icmpge: // fall through
      case Bytecodes::_if_icmpgt: // fall through
      case Bytecodes::_if_icmple: // fall through
      case Bytecodes::_if_acmpeq: // fall through
      case Bytecodes::_if_acmpne: // fall through
      case Bytecodes::_ifnull:    // fall through
      case Bytecodes::_ifnonnull:
        if (s.next_bci() < end_bci) {
          make_block_at(s.next_bci(), current);
        }
        make_block_at(s.get_dest(), current);
        current = nullptr;
        break;

      case Bytecodes::_goto:
        make_block_at(s.get_dest(), current);
        current = nullptr;
        break;

      case Bytecodes::_goto_w:
        make_block_at(s.get_far_dest(), current);
        current = nullptr;
        break;

      case Bytecodes::_jsr:
        handle_jsr(current, s.get_dest(), s.next_bci());
        current = nullptr;
        break;

      case Bytecodes::_jsr_w:
        handle_jsr(current, s.get_far_dest(), s.next_bci());
        current = nullptr;
        break;

      case Bytecodes::_tableswitch: {
        // set block for each case
        Bytecode_tableswitch sw(&s);
        int l = sw.length();
        for (int i = 0; i < l; i++) {
          make_block_at(cur_bci + sw.dest_offset_at(i), current);
        }
        make_block_at(cur_bci + sw.default_offset(), current);
        current = nullptr;
        break;
      }

      case Bytecodes::_lookupswitch: {
        // set block for each case
        Bytecode_lookupswitch sw(&s);
        int l = sw.number_of_pairs();
        for (int i = 0; i < l; i++) {
          make_block_at(cur_bci + sw.pair_at(i).offset(), current);
        }
        make_block_at(cur_bci + sw.default_offset(), current);
        current = nullptr;
        break;
      }

      default:
        break;
    }
  }
}
```

在如上函数中，由于是在创建控制流图，而HIR的控制流图是双向链接的，也就是说每个基本块都有指向前驱节点（predecessor）和指向后继节点（successor）的指针。并且控制流图的基本块的划分原则是：

- 方法的第1个字节码指令
- 控制转移指令的目标位置
- 控制转移指令的下一条字节码指令

所以如上函数重点处理了控制转移指令，并且建立了基本块前驱和后续节点的相关信息。

调用ciMethod类的bci_block_start()函数，这个函数主要通过位来标注每个基本块中开始的第一个字节码位置



```cpp
// Marks all bcis where a new basic block starts
const BitMap& ciMethod::bci_block_start() {
  check_is_loaded();
  if (_liveness == nullptr) {
    // Create the liveness analyzer.
    Arena* arena = CURRENT_ENV->arena();
    _liveness = new (arena) MethodLiveness(arena, this);
    _liveness->compute_liveness();
  }

  return _liveness->get_bci_block_start();
}
```

### compute_liveness

```cpp
void MethodLiveness::compute_liveness() {
  init_basic_blocks();
  init_gen_kill();
  propagate_liveness();
}
```





```cpp
void MethodLiveness::init_basic_blocks() {
  int method_len = method()->code_size();
  ciMethodBlocks *mblocks = method()->get_method_blocks();

  // Create an array to store the bci->BasicBlock mapping.
  _block_map = new (arena()) GrowableArray<BasicBlock*>(arena(), method_len, method_len, nullptr);

  _block_count = mblocks->num_blocks();
  _block_list = (BasicBlock **) arena()->Amalloc(sizeof(BasicBlock *) * _block_count);

  // Used for patching up jsr/ret control flow.
  GrowableArray<BasicBlock*>* jsr_exit_list = new GrowableArray<BasicBlock*>(5);
  GrowableArray<BasicBlock*>* ret_list = new GrowableArray<BasicBlock*>(5);

  // generate our block list from ciMethodBlocks
  for (int blk = 0; blk < _block_count; blk++) {
    ciBlock *cib = mblocks->block(blk);
     int start_bci = cib->start_bci();
    _block_list[blk] = new (arena()) BasicBlock(this, start_bci, cib->limit_bci());
    _block_map->at_put(start_bci, _block_list[blk]);
#ifdef COMPILER1
    // mark all bcis where a new basic block starts
    _bci_block_start.set_bit(start_bci);
#endif // COMPILER1
  }
  // fill in the predecessors of blocks
  ciBytecodeStream bytes(method());

  for (int blk = 0; blk < _block_count; blk++) {
    BasicBlock *current_block = _block_list[blk];
    int bci =  mblocks->block(blk)->control_bci();

    if (bci == ciBlock::fall_through_bci) {
      int limit = current_block->limit_bci();
      if (limit < method_len) {
        BasicBlock *next = _block_map->at(limit);
        assert( next != nullptr, "must be a block immediately following this one.");
        next->add_normal_predecessor(current_block);
      }
      continue;
    }
    bytes.reset_to_bci(bci);
    Bytecodes::Code code = bytes.next();
    BasicBlock *dest;

    // Now we need to interpret the instruction's effect
    // on control flow.
    assert (current_block != nullptr, "we must have a current block");
    switch (code) {
      case Bytecodes::_ifeq:
      case Bytecodes::_ifne:
      case Bytecodes::_iflt:
      case Bytecodes::_ifge:
      case Bytecodes::_ifgt:
      case Bytecodes::_ifle:
      case Bytecodes::_if_icmpeq:
      case Bytecodes::_if_icmpne:
      case Bytecodes::_if_icmplt:
      case Bytecodes::_if_icmpge:
      case Bytecodes::_if_icmpgt:
      case Bytecodes::_if_icmple:
      case Bytecodes::_if_acmpeq:
      case Bytecodes::_if_acmpne:
      case Bytecodes::_ifnull:
      case Bytecodes::_ifnonnull:
        // Two way branch.  Set predecessors at each destination.
        if (bytes.next_bci() < method_len) {
          dest = _block_map->at(bytes.next_bci());
          assert(dest != nullptr, "must be a block immediately following this one.");
          dest->add_normal_predecessor(current_block);
        }
        dest = _block_map->at(bytes.get_dest());
        assert(dest != nullptr, "branch destination must start a block.");
        dest->add_normal_predecessor(current_block);
        break;
      case Bytecodes::_goto:
        dest = _block_map->at(bytes.get_dest());
        assert(dest != nullptr, "branch destination must start a block.");
        dest->add_normal_predecessor(current_block);
        break;
      case Bytecodes::_goto_w:
        dest = _block_map->at(bytes.get_far_dest());
        assert(dest != nullptr, "branch destination must start a block.");
        dest->add_normal_predecessor(current_block);
        break;
      case Bytecodes::_tableswitch:
        {
          Bytecode_tableswitch tableswitch(&bytes);

          int len = tableswitch.length();

          dest = _block_map->at(bci + tableswitch.default_offset());
          assert(dest != nullptr, "branch destination must start a block.");
          dest->add_normal_predecessor(current_block);
          while (--len >= 0) {
            dest = _block_map->at(bci + tableswitch.dest_offset_at(len));
            assert(dest != nullptr, "branch destination must start a block.");
            dest->add_normal_predecessor(current_block);
          }
          break;
        }

      case Bytecodes::_lookupswitch:
        {
          Bytecode_lookupswitch lookupswitch(&bytes);

          int npairs = lookupswitch.number_of_pairs();

          dest = _block_map->at(bci + lookupswitch.default_offset());
          assert(dest != nullptr, "branch destination must start a block.");
          dest->add_normal_predecessor(current_block);
          while(--npairs >= 0) {
            LookupswitchPair pair = lookupswitch.pair_at(npairs);
            dest = _block_map->at( bci + pair.offset());
            assert(dest != nullptr, "branch destination must start a block.");
            dest->add_normal_predecessor(current_block);
          }
          break;
        }

      case Bytecodes::_jsr:
        {
          assert(bytes.is_wide()==false, "sanity check");
          dest = _block_map->at(bytes.get_dest());
          assert(dest != nullptr, "branch destination must start a block.");
          dest->add_normal_predecessor(current_block);
          BasicBlock *jsrExit = _block_map->at(current_block->limit_bci());
          assert(jsrExit != nullptr, "jsr return bci must start a block.");
          jsr_exit_list->append(jsrExit);
          break;
        }
      case Bytecodes::_jsr_w:
        {
          dest = _block_map->at(bytes.get_far_dest());
          assert(dest != nullptr, "branch destination must start a block.");
          dest->add_normal_predecessor(current_block);
          BasicBlock *jsrExit = _block_map->at(current_block->limit_bci());
          assert(jsrExit != nullptr, "jsr return bci must start a block.");
          jsr_exit_list->append(jsrExit);
          break;
        }

      case Bytecodes::_wide:
        assert(false, "wide opcodes should not be seen here");
        break;
      case Bytecodes::_athrow:
      case Bytecodes::_ireturn:
      case Bytecodes::_lreturn:
      case Bytecodes::_freturn:
      case Bytecodes::_dreturn:
      case Bytecodes::_areturn:
      case Bytecodes::_return:
        // These opcodes are  not the normal predecessors of any other opcodes.
        break;
      case Bytecodes::_ret:
        // We will patch up jsr/rets in a subsequent pass.
        ret_list->append(current_block);
        break;
      default:
        // Do nothing.
        break;
    }
  }
  // Patch up the jsr/ret's.  We conservatively assume that any ret
  // can return to any jsr site.
  int ret_list_len = ret_list->length();
  int jsr_exit_list_len = jsr_exit_list->length();
  if (ret_list_len > 0 && jsr_exit_list_len > 0) {
    for (int i = jsr_exit_list_len - 1; i >= 0; i--) {
      BasicBlock *jsrExit = jsr_exit_list->at(i);
      for (int i = ret_list_len - 1; i >= 0; i--) {
        jsrExit->add_normal_predecessor(ret_list->at(i));
      }
    }
  }

  // Compute exception edges.
  for (int b=_block_count-1; b >= 0; b--) {
    BasicBlock *block = _block_list[b];
    int block_start = block->start_bci();
    int block_limit = block->limit_bci();
    ciExceptionHandlerStream handlers(method());
    for (; !handlers.is_done(); handlers.next()) {
      ciExceptionHandler* handler = handlers.handler();
      int start       = handler->start();
      int limit       = handler->limit();
      int handler_bci = handler->handler_bci();

      int intersect_start = MAX2(block_start, start);
      int intersect_limit = MIN2(block_limit, limit);
      if (intersect_start < intersect_limit) {
        // The catch range has a nonempty intersection with this
        // basic block.  That means this basic block can be an
        // exceptional predecessor.
        _block_map->at(handler_bci)->add_exception_predecessor(block);

        if (handler->is_catch_all()) {
          // This is a catch-all block.
          if (intersect_start == block_start && intersect_limit == block_limit) {
            // The basic block is entirely contained in this catch-all block.
            // Skip the rest of the exception handlers -- they can never be
            // reached in execution.
            break;
          }
        }
      }
    }
  }
}
```







```cpp
ciMethodBlocks  *ciMethod::get_method_blocks() {
  if (_method_blocks == nullptr) {
    Arena *arena = CURRENT_ENV->arena();
    _method_blocks = new (arena) ciMethodBlocks(arena, this);
  }
  return _method_blocks;
}
```





ciMethodBlocks类的构造函数

```cpp
ciMethodBlocks::ciMethodBlocks(Arena *arena, ciMethod *meth): _method(meth),
                          _arena(arena), _num_blocks(0), _code_size(meth->code_size()) {
  int block_estimate = _code_size / 8;

  _blocks =  new(_arena) GrowableArray<ciBlock *>(_arena, block_estimate, 0, nullptr);
  int b2bsize = _code_size * sizeof(ciBlock **);
  _bci_to_block = (ciBlock **) arena->Amalloc(b2bsize);
  Copy::zero_to_words((HeapWord*) _bci_to_block, b2bsize / sizeof(HeapWord));

  // create initial block covering the entire method
  ciBlock *b = new(arena) ciBlock(_method, _num_blocks++, 0);
  _blocks->append(b);
  _bci_to_block[0] = b;

  // create blocks for exception handlers
  if (meth->has_exception_handlers()) {
    for(ciExceptionHandlerStream str(meth); !str.is_done(); str.next()) {
      ciExceptionHandler* handler = str.handler();
      ciBlock *eb = make_block_at(handler->handler_bci());
      //
      // Several exception handlers can have the same handler_bci:
      //
      //  try {
      //    if (a.foo(b) < 0) {
      //      return a.error();
      //    }
      //    return CoderResult.UNDERFLOW;
      //  } finally {
      //      a.position(b);
      //  }
      //
      //  The try block above is divided into 2 exception blocks
      //  separated by 'areturn' bci.
      //
      int ex_start = handler->start();
      int ex_end = handler->limit();
      // ensure a block at the start of exception range and start of following code
      (void) make_block_at(ex_start);
      if (ex_end < _code_size)
        (void) make_block_at(ex_end);

      if (eb->is_handler()) {
        // Extend old handler exception range to cover additional range.
        int old_ex_start = eb->ex_start_bci();
        int old_ex_end   = eb->ex_limit_bci();
        if (ex_start > old_ex_start)
          ex_start = old_ex_start;
        if (ex_end < old_ex_end)
          ex_end = old_ex_end;
        eb->clear_exception_handler(); // Reset exception information
      }
      eb->set_exception_range(ex_start, ex_end);
    }
  }

  // scan the bytecodes and identify blocks
  do_analysis();

  // mark blocks that have exception handlers
  if (meth->has_exception_handlers()) {
    for(ciExceptionHandlerStream str(meth); !str.is_done(); str.next()) {
      ciExceptionHandler* handler = str.handler();
      int ex_start = handler->start();
      int ex_end = handler->limit();

      int bci = ex_start;
      while (bci < ex_end) {
        ciBlock *b = block_containing(bci);
        b->set_has_handler();
        bci = b->limit_bci();
      }
    }
  }
}
```





#### do_analysis

```cpp
void ciMethodBlocks::do_analysis() {
  ciBytecodeStream s(_method);
  ciBlock *cur_block = block_containing(0);
  int limit_bci = _method->code_size();

  while (s.next() != ciBytecodeStream::EOBC()) {
    int bci = s.cur_bci();
    // Determine if a new block has been made at the current bci.  If
    // this block differs from our current range, switch to the new
    // one and end the old one.
    assert(cur_block != nullptr, "must always have a current block");
    ciBlock *new_block = block_containing(bci);
    if (new_block == nullptr || new_block == cur_block) {
      // We have not marked this bci as the start of a new block.
      // Keep interpreting the current_range.
      _bci_to_block[bci] = cur_block;
    } else {
      cur_block->set_limit_bci(bci);
      cur_block = new_block;
    }

    switch (s.cur_bc()) {
      case Bytecodes::_ifeq        :
      case Bytecodes::_ifne        :
      case Bytecodes::_iflt        :
      case Bytecodes::_ifge        :
      case Bytecodes::_ifgt        :
      case Bytecodes::_ifle        :
      case Bytecodes::_if_icmpeq   :
      case Bytecodes::_if_icmpne   :
      case Bytecodes::_if_icmplt   :
      case Bytecodes::_if_icmpge   :
      case Bytecodes::_if_icmpgt   :
      case Bytecodes::_if_icmple   :
      case Bytecodes::_if_acmpeq   :
      case Bytecodes::_if_acmpne   :
      case Bytecodes::_ifnull      :
      case Bytecodes::_ifnonnull   :
      {
        cur_block->set_control_bci(bci);
        if (s.next_bci() < limit_bci) {
          ciBlock *fall_through = make_block_at(s.next_bci());
        }
        int dest_bci = s.get_dest();
        ciBlock *dest = make_block_at(dest_bci);
        break;
      }

      case Bytecodes::_goto        :
      {
        cur_block->set_control_bci(bci);
        if (s.next_bci() < limit_bci) {
          (void) make_block_at(s.next_bci());
        }
        int dest_bci = s.get_dest();
        ciBlock *dest = make_block_at(dest_bci);
        break;
      }

      case Bytecodes::_jsr         :
      {
        cur_block->set_control_bci(bci);
        if (s.next_bci() < limit_bci) {
          ciBlock *ret = make_block_at(s.next_bci());
        }
        int dest_bci = s.get_dest();
        ciBlock *dest = make_block_at(dest_bci);
        break;
      }

      case Bytecodes::_tableswitch :
        {
          cur_block->set_control_bci(bci);
          Bytecode_tableswitch sw(&s);
          int len = sw.length();
          ciBlock *dest;
          int dest_bci;
          for (int i = 0; i < len; i++) {
            dest_bci = s.cur_bci() + sw.dest_offset_at(i);
            dest = make_block_at(dest_bci);
          }
          dest_bci = s.cur_bci() + sw.default_offset();
          make_block_at(dest_bci);
          if (s.next_bci() < limit_bci) {
            dest = make_block_at(s.next_bci());
          }
        }
        break;

      case Bytecodes::_lookupswitch:
        {
          cur_block->set_control_bci(bci);
          Bytecode_lookupswitch sw(&s);
          int len = sw.number_of_pairs();
          ciBlock *dest;
          int dest_bci;
          for (int i = 0; i < len; i++) {
            dest_bci = s.cur_bci() + sw.pair_at(i).offset();
            dest = make_block_at(dest_bci);
          }
          dest_bci = s.cur_bci() + sw.default_offset();
          dest = make_block_at(dest_bci);
          if (s.next_bci() < limit_bci) {
            dest = make_block_at(s.next_bci());
          }
        }
        break;

      case Bytecodes::_goto_w      :
      {
        cur_block->set_control_bci(bci);
        if (s.next_bci() < limit_bci) {
          (void) make_block_at(s.next_bci());
        }
        int dest_bci = s.get_far_dest();
        ciBlock *dest = make_block_at(dest_bci);
        break;
      }

      case Bytecodes::_jsr_w       :
      {
        cur_block->set_control_bci(bci);
        if (s.next_bci() < limit_bci) {
          ciBlock *ret = make_block_at(s.next_bci());
        }
        int dest_bci = s.get_far_dest();
        ciBlock *dest = make_block_at(dest_bci);
        break;
      }

      case Bytecodes::_athrow      :
        cur_block->set_may_throw();
        // fall-through
      case Bytecodes::_ret         :
      case Bytecodes::_ireturn     :
      case Bytecodes::_lreturn     :
      case Bytecodes::_freturn     :
      case Bytecodes::_dreturn     :
      case Bytecodes::_areturn     :
      case Bytecodes::_return      :
        cur_block->set_control_bci(bci);
        if (s.next_bci() < limit_bci) {
          (void) make_block_at(s.next_bci());
        }
        break;

      default:
        break;
    }
  }
  //  End the last block
  cur_block->set_limit_bci(limit_bci);
}
```



对ciMethodBlocks类中的_blocks（类型为ciBlock*）和_bci_to_block（类型为ciBlock***，通过二维数组存储字节码到块的映射）属性填充。其中处理的指令都是控制转移相关的字节码指令，因为这些指令会影响到基本块的划分。我们始终要记住基本块的划分原理，这样上面的代码就很容易理解。如ifxx系列指令，目标位置是一个基本块的起始位置，而指令的下一个位置也是一个基本块的起始位置，所以我们要调用mark_block_at()函数来创建或查找属于这些位置的基本块

```cpp
ciBlock *ciMethodBlocks::make_block_at(int bci) {
  ciBlock *cb = block_containing(bci);
  if (cb == nullptr ) {
    // This is our first time visiting this bytecode.  Create
    // a fresh block and assign it this starting point.
    ciBlock *nb = new(_arena) ciBlock(_method, _num_blocks++, bci);
    _blocks->append(nb);
     _bci_to_block[bci] = nb;
    return nb;
  } else if (cb->start_bci() == bci) {
    // The block begins at bci.  Simply return it.
    return cb;
  } else {
    // We have already created a block containing bci but
    // not starting at bci.  This existing block needs to
    // be split into two.
    return split_block_at(bci);
  }
}
```







```cpp
// Split the block spanning bci into two separate ranges.  The former
// block becomes the second half and a new range is created for the
// first half.  Returns the range beginning at bci.
ciBlock *ciMethodBlocks::split_block_at(int bci) {
  ciBlock *former_block = block_containing(bci);
  ciBlock *new_block = new(_arena) ciBlock(_method, _num_blocks++, former_block->start_bci());
  _blocks->append(new_block);
  assert(former_block != nullptr, "must not be nullptr");
  new_block->set_limit_bci(bci);
  former_block->set_start_bci(bci);
  for (int pos=bci-1; pos >= 0; pos--) {
    ciBlock *current_block = block_containing(pos);
    if (current_block == former_block) {
      // Replace it.
      _bci_to_block[pos] = new_block;
    } else if (current_block == nullptr) {
      // Non-bytecode start.  Skip.
      continue;
    } else {
      // We are done with our backwards walk
      break;
    }
  }
  // Move an exception handler information if needed.
  if (former_block->is_handler()) {
    int ex_start = former_block->ex_start_bci();
    int ex_end = former_block->ex_limit_bci();
    new_block->set_exception_range(ex_start, ex_end);
    // Clear information in former_block.
    former_block->clear_exception_handler();
  }
  return former_block;
}
```



## build



MethodData类中定义了一个_data属性，这个属性会记录函数运行状态下的数据。主要记录3部分的数据，一个是函数类型等运行相关统计数据，一个是参数类型运行相关统计数据，还有一个是extra扩展区保存着deoptimization的相关信息，是C2优化的基础；MethodCounters主要用于基于调用频率的热点方法或块的跟踪统计

```cpp
class Method : public Metadata {
 private:
  // If you add a new field that points to any metaspace object, you
  // must add this field to Method::metaspace_pointers_do().
  ConstMethod*      _constMethod;                // Method read-only data.
  MethodData*       _method_data;
  MethodCounters*   _method_counters;
  // ...
};
```

MethodData类中定义了一个_data属性，这个属性会记录函数运行状态下的数据。主要记录3部分的数据，一个是函数类型等运行相关统计数据，一个是参数类型运行相关统计数据，还有一个是extra扩展区保存着deoptimization的相关信息，是C2优化的基础；MethodCounters主要用于基于调用频率的热点方法或块的跟踪统计

```cpp

class MethodData : public Metadata {
private:
  // How many invocations has this MDO seen?
  // These counters are used to determine the exact age of MDO.
  // We need those because in tiered a method can be concurrently
  // executed at different levels.
  InvocationCounter _invocation_counter;
  // Same for backedges.
  InvocationCounter _backedge_counter;

  // Beginning of the data entries
  intptr_t _data[1];
 // ...
};
```



MethodCounters用于热点代码跟踪中的方法调用计数和回边计数

```cpp
class MethodCounters : public Metadata {
 private:
  InvocationCounter _invocation_counter;         // Incremented before each activation of the method - used to trigger frequency-based optimizations
  InvocationCounter _backedge_counter;
};
```

将统计相关的信息存储到MerthodData和MethodCounters中的相关属性上，主要是_invocation_counter和_backedge_counter属性



为了尽可能节省内存空间，HotSpot VM使用_counter记录多个数据信息，这是一个整数类型的组合数字， counter、carry、state 三个字段用一个32位 int 类型数据表示

```cpp
class InvocationCounter {
 private:              // bit no: |31  1|  0  |
  uint _counter;       // format: [count|carry|

};
```

TemplateInterpreterGenerator::generate_normal_entry 和 TemplateInterpreterGenerator::generate_native_entry 二者调用的逻辑相同 如下



```cpp

// determine code generation flags
bool inc_counter  = UseCompiler || CountCompiledCalls;

// increment invocation count & check for overflow
Label invocation_counter_overflow;
if (inc_counter) {
    generate_counter_incr(&invocation_counter_overflow);
}

// 在dispatch_next之前
Label continue_after_compile;
__ bind(continue_after_compile);


// ... 正常执行到此

// invocation counter overflow
if (inc_counter) {
    // Handle overflow of counter and compile method
    __ bind(invocation_counter_overflow);
    generate_counter_overflow(continue_after_compile);
}
```





下面开始介绍解释执行时的方法调用计数逻辑



ProfilerInterpreter选项为true情况下是先MethodData中的计数（因为MethodData能更精确的记录更多运行时数据）之后才会使用MethodCounters



```cpp
// x86
void TemplateInterpreterGenerator::generate_counter_incr(Label* overflow) {
  Label done;
  // Note: In tiered we increment either counters in Method* or in MDO depending if we're profiling or not.
  Label no_mdo;
  if (ProfileInterpreter) {
    // Are we profiling?
    __ movptr(rax, Address(rbx, Method::method_data_offset()));
    __ testptr(rax, rax);
    __ jccb(Assembler::zero, no_mdo);
    // Increment counter in the MDO
    const Address mdo_invocation_counter(rax, in_bytes(MethodData::invocation_counter_offset()) +
        in_bytes(InvocationCounter::counter_offset()));
    const Address mask(rax, in_bytes(MethodData::invoke_mask_offset()));
    __ increment_mask_and_jump(mdo_invocation_counter, mask, rcx, overflow);
    __ jmp(done);
  }
  __ bind(no_mdo);
  // Increment counter in MethodCounters
  const Address invocation_counter(rax,
      MethodCounters::invocation_counter_offset() +
      InvocationCounter::counter_offset());
  __ get_method_counters(rbx, rax, done);
  const Address mask(rax, in_bytes(MethodCounters::invoke_mask_offset()));
  __ increment_mask_and_jump(invocation_counter, mask, rcx, overflow);
  __ bind(done);
}
```



跳转到do_continue 此处为continue_after_compile处

continue_after_compile处的例程在dispatch_next()函数生成的例程之前

```cpp
void TemplateInterpreterGenerator::generate_counter_overflow(Label& do_continue) {

  // Asm interpreter on entry
  // r14/rdi - locals
  // r13/rsi - bcp
  // rbx - method
  // rdx - cpool --- DOES NOT APPEAR TO BE TRUE
  // rbp - interpreter frame

  // On return (i.e. jump to entry_point) [ back to invocation of interpreter ]
  // Everything as it was on entry
  // rdx is not restored. Doesn't appear to really be set.

  // InterpreterRuntime::frequency_counter_overflow takes two
  // arguments, the first (thread) is passed by call_VM, the second
  // indicates if the counter overflow occurs at a backwards branch
  // (null bcp).  We pass zero for it.  The call returns the address
  // of the verified entry point for the method or null if the
  // compilation did not complete (either went background or bailed
  // out).
  Register rarg = NOT_LP64(rax) LP64_ONLY(c_rarg1);
  __ movl(rarg, 0);
  __ call_VM(noreg,
             CAST_FROM_FN_PTR(address,
                              InterpreterRuntime::frequency_counter_overflow),
             rarg);

  __ movptr(rbx, Address(rbp, method_offset));   // restore Method*
  // Preserve invariant that r13/r14 contain bcp/locals of sender frame
  // and jump to the interpreted entry.
  __ jmp(do_continue, relocInfo::none);
}
```

编译热点代码块时，如果调用InterpreterRuntime::frequency_counter_overflow()函数获取到了合适的编译结果，那么就需要执行栈上替换了



```cpp
nmethod* InterpreterRuntime::frequency_counter_overflow(JavaThread* current, address branch_bcp) {
  // Enable WXWrite: the function is called directly by interpreter.
  MACOS_AARCH64_ONLY(ThreadWXEnable wx(WXWrite, current));

  // frequency_counter_overflow_inner can throw async exception.
  nmethod* nm = frequency_counter_overflow_inner(current, branch_bcp);
  assert(branch_bcp != nullptr || nm == nullptr, "always returns null for non OSR requests");
  if (branch_bcp != nullptr && nm != nullptr) {
    // This was a successful request for an OSR nmethod.  Because
    // frequency_counter_overflow_inner ends with a safepoint check,
    // nm could have been unloaded so look it up again.  It's unsafe
    // to examine nm directly since it might have been freed and used
    // for something else.
    LastFrameAccessor last_frame(current);
    Method* method =  last_frame.method();
    int bci = method->bci_from(last_frame.bcp());
    nm = method->lookup_osr_nmethod_for(bci, CompLevel_none, false);
    BarrierSetNMethod* bs_nm = BarrierSet::barrier_set()->barrier_set_nmethod();
    if (nm != nullptr && bs_nm != nullptr) {
      // in case the transition passed a safepoint we need to barrier this again
      if (!bs_nm->nmethod_osr_entry_barrier(nm)) {
        nm = nullptr;
      }
    }
  }
  if (nm != nullptr && current->is_interp_only_mode()) {
    // Normally we never get an nm if is_interp_only_mode() is true, because
    // policy()->event has a check for this and won't compile the method when
    // true. However, it's possible for is_interp_only_mode() to become true
    // during the compilation. We don't want to return the nm in that case
    // because we want to continue to execute interpreted.
    nm = nullptr;
  }
#ifndef PRODUCT
  if (TraceOnStackReplacement) {
    if (nm != nullptr) {
      tty->print("OSR entry @ pc: " INTPTR_FORMAT ": ", p2i(nm->osr_entry()));
      nm->print();
    }
  }
#endif
  return nm;
}
```









```cpp
void Compilation::install_code(int frame_size) {
  // frame_size is in 32-bit words so adjust it intptr_t words
  assert(frame_size == frame_map()->framesize(), "must match");
  assert(in_bytes(frame_map()->framesize_in_bytes()) % sizeof(intptr_t) == 0, "must be at least pointer aligned");
  _env->register_method(
    method(),
    osr_bci(),
    &_offsets,
    in_bytes(_frame_map->sp_offset_for_orig_pc()),
    code(),
    in_bytes(frame_map()->framesize_in_bytes()) / sizeof(intptr_t),
    debug_info_recorder()->_oopmaps,
    exception_handler_table(),
    implicit_exception_table(),
    compiler(),
    has_unsafe_access(),
    SharedRuntime::is_wide_vector(max_vector_size()),
    has_monitors(),
    _immediate_oops_patched
  );
}
```

创建一个nmethod实例来表示编译后的方法

从codecache中获取

如果是OSR *将其添加到Klass的osr_nmethods链表上 否则* 会将编译完成后的方法设置到Method::_code属性上

在HotSpot VM的实现里，一般一个类被加载进来之后，里面的方法最早也要到它即将第一次被执行的时候才有可能被JIT编译器所编译。在那之前，非abstract非native的Java方法都只是以Java字节码的形式存在，没有对应的机器码（上面所说的 Method::_code属性的值为NULL）

如果在调用方法时，会检测Method::_code属性，如果不为空，则执行编译完成后的方法



```cpp
void ciEnv::register_method(ciMethod* target,
                            int entry_bci,
                            CodeOffsets* offsets,
                            int orig_pc_offset,
                            CodeBuffer* code_buffer,
                            int frame_words,
                            OopMapSet* oop_map_set,
                            ExceptionHandlerTable* handler_table,
                            ImplicitExceptionTable* inc_table,
                            AbstractCompiler* compiler,
                            bool has_unsafe_access,
                            bool has_wide_vectors,
                            bool has_monitors,
                            int immediate_oops_patched,
                            RTMState  rtm_state) {
  VM_ENTRY_MARK;
  nmethod* nm = nullptr;
  {
    methodHandle method(THREAD, target->get_Method());

    // We require method counters to store some method state (max compilation levels) required by the compilation policy.
    if (method->get_method_counters(THREAD) == nullptr) {
      record_failure("can't create method counters");
      // All buffers in the CodeBuffer are allocated in the CodeCache.
      // If the code buffer is created on each compile attempt
      // as in C2, then it must be freed.
      code_buffer->free_blob();
      return;
    }

    // Check if memory should be freed before allocation
    CodeCache::gc_on_allocation();

    // To prevent compile queue updates.
    MutexLocker locker(THREAD, MethodCompileQueue_lock);

    // Prevent InstanceKlass::add_to_hierarchy from running
    // and invalidating our dependencies until we install this method.
    // No safepoints are allowed. Otherwise, class redefinition can occur in between.
    MutexLocker ml(Compile_lock);
    NoSafepointVerifier nsv;

    // Change in Jvmti state may invalidate compilation.
    if (!failing() && jvmti_state_changed()) {
      record_failure("Jvmti state change invalidated dependencies");
    }

    // Change in DTrace flags may invalidate compilation.
    if (!failing() &&
        ( (!dtrace_method_probes() && DTraceMethodProbes) ||
          (!dtrace_alloc_probes() && DTraceAllocProbes) )) {
      record_failure("DTrace flags change invalidated dependencies");
    }

    if (!failing() && target->needs_clinit_barrier() &&
        target->holder()->is_in_error_state()) {
      record_failure("method holder is in error state");
    }

    if (!failing()) {
      if (log() != nullptr) {
        // Log the dependencies which this compilation declares.
        dependencies()->log_all_dependencies();
      }

      // Encode the dependencies now, so we can check them right away.
      dependencies()->encode_content_bytes();

      // Check for {class loads, evolution, breakpoints, ...} during compilation
      validate_compile_task_dependencies(target);
    }

    if (failing()) {
      // While not a true deoptimization, it is a preemptive decompile.
      MethodData* mdo = method()->method_data();
      if (mdo != nullptr && _inc_decompile_count_on_failure) {
        mdo->inc_decompile_count();
      }

      // All buffers in the CodeBuffer are allocated in the CodeCache.
      // If the code buffer is created on each compile attempt
      // as in C2, then it must be freed.
      code_buffer->free_blob();
      return;
    }

    nm =  nmethod::new_nmethod(method,
                               compile_id(),
                               entry_bci,
                               offsets,
                               orig_pc_offset,
                               debug_info(), dependencies(), code_buffer,
                               frame_words, oop_map_set,
                               handler_table, inc_table,
                               compiler, CompLevel(task()->comp_level()));

    // Free codeBlobs
    code_buffer->free_blob();

    if (nm != nullptr) {
      nm->set_has_unsafe_access(has_unsafe_access);
      nm->set_has_wide_vectors(has_wide_vectors);
      nm->set_has_monitors(has_monitors);
      assert(!method->is_synchronized() || nm->has_monitors(), "");
#if INCLUDE_RTM_OPT
      nm->set_rtm_state(rtm_state);
#endif

      if (entry_bci == InvocationEntryBci) {
        if (TieredCompilation) {
          // If there is an old version we're done with it
          CompiledMethod* old = method->code();
          if (TraceMethodReplacement && old != nullptr) {
            ResourceMark rm;
            char *method_name = method->name_and_sig_as_C_string();
            tty->print_cr("Replacing method %s", method_name);
          }
          if (old != nullptr) {
            old->make_not_used();
          }
        }

        LogTarget(Info, nmethod, install) lt;
        if (lt.is_enabled()) {
          ResourceMark rm;
          char *method_name = method->name_and_sig_as_C_string();
          lt.print("Installing method (%d) %s ",
                    task()->comp_level(), method_name);
        }
        // Allow the code to be executed
        MutexLocker ml(CompiledMethod_lock, Mutex::_no_safepoint_check_flag);
        if (nm->make_in_use()) {
          method->set_code(method, nm);
        }
      } else {
        LogTarget(Info, nmethod, install) lt;
        if (lt.is_enabled()) {
          ResourceMark rm;
          char *method_name = method->name_and_sig_as_C_string();
          lt.print("Installing osr method (%d) %s @ %d",
                    task()->comp_level(), method_name, entry_bci);
        }
        MutexLocker ml(CompiledMethod_lock, Mutex::_no_safepoint_check_flag);
        if (nm->make_in_use()) {
          method->method_holder()->add_osr_nmethod(nm);
        }
      }
    }
  }

  NoSafepointVerifier nsv;
  if (nm != nullptr) {
    // Compilation succeeded, post what we know about it
    nm->post_compiled_method(task());
    task()->set_num_inlined_bytecodes(num_inlined_bytecodes());
  } else {
    // The CodeCache is full.
    record_failure("code cache is full");
  }

  // safepoints are allowed again
}
```



其实就是把nmethod与其对应的Method关联起来，把各入口都设置上。设置Method::_code、Method::_from_compiled_entry和Method::_from_interpreted_entry属性



```cpp
// Install compiled code.  Instantly it can execute.
void Method::set_code(const methodHandle& mh, CompiledMethod *code) {
  guarantee(mh->adapter() != nullptr, "Adapter blob must already exist!");

  // These writes must happen in this order, because the interpreter will
  // directly jump to from_interpreted_entry which jumps to an i2c adapter
  // which jumps to _from_compiled_entry.
  mh->_code = code;             // Assign before allowing compiled code to exec

  int comp_level = code->comp_level();
  // In theory there could be a race here. In practice it is unlikely
  // and not worth worrying about.
  if (comp_level > mh->highest_comp_level()) {
    mh->set_highest_comp_level(comp_level);
  }

  OrderAccess::storestore();
  mh->_from_compiled_entry = code->verified_entry_point();
  OrderAccess::storestore();

  if (mh->is_continuation_native_intrinsic()) {
    assert(mh->_from_interpreted_entry == nullptr, "initialized incorrectly"); // see link_method

    if (mh->is_continuation_enter_intrinsic()) {
      // This is the entry used when we're in interpreter-only mode; see InterpreterMacroAssembler::jump_from_interpreted
      mh->_i2i_entry = ContinuationEntry::interpreted_entry();
    } else if (mh->is_continuation_yield_intrinsic()) {
      mh->_i2i_entry = mh->get_i2c_entry();
    } else {
      guarantee(false, "Unknown Continuation native intrinsic");
    }
    // This must come last, as it is what's tested in LinkResolver::resolve_static_call
    Atomic::release_store(&mh->_from_interpreted_entry , mh->get_i2c_entry());
  } else if (!mh->is_method_handle_intrinsic()) {
    // Instantly compiled code can execute.
    mh->_from_interpreted_entry = mh->get_i2c_entry();
  }
}
```

add_osr_nmethod()函数用于将需要执行栈上替换的nmethod实例插入到InstanceKlass的osr_nmethods链表上

```cpp
// On-stack replacement stuff
void InstanceKlass::add_osr_nmethod(nmethod* n) {
  assert_lock_strong(CompiledMethod_lock);
#ifndef PRODUCT
  nmethod* prev = lookup_osr_nmethod(n->method(), n->osr_entry_bci(), n->comp_level(), true);
  assert(prev == nullptr || !prev->is_in_use() COMPILER2_PRESENT(|| StressRecompilation),
      "redundant OSR recompilation detected. memory leak in CodeCache!");
#endif
  // only one compilation can be active
  assert(n->is_osr_method(), "wrong kind of nmethod");
  n->set_osr_link(osr_nmethods_head());
  set_osr_nmethods_head(n);
  // Raise the highest osr level if necessary
  n->method()->set_highest_osr_comp_level(MAX2(n->method()->highest_osr_comp_level(), n->comp_level()));

  // Get rid of the osr methods for the same bci that have lower levels.
  for (int l = CompLevel_limited_profile; l < n->comp_level(); l++) {
    nmethod *inv = lookup_osr_nmethod(n->method(), n->osr_entry_bci(), l, true);
    if (inv != nullptr && inv->is_in_use()) {
      inv->make_not_entrant();
    }
  }
}
```

与add_osr_nmethod()函数相对应的就是remove_osr_nmethod()函数，用于从osr_nmethod链表上移除nmethod，当nmethod被标记成not_entrant或者zombie时，或者执行CodeCache垃圾回收时会调用该函数



```cpp
// Remove osr nmethod from the list. Return true if found and removed.
bool InstanceKlass::remove_osr_nmethod(nmethod* n) {
  // This is a short non-blocking critical region, so the no safepoint check is ok.
  MutexLocker ml(CompiledMethod_lock->owned_by_self() ? nullptr : CompiledMethod_lock
                 , Mutex::_no_safepoint_check_flag);
  assert(n->is_osr_method(), "wrong kind of nmethod");
  nmethod* last = nullptr;
  nmethod* cur  = osr_nmethods_head();
  int max_level = CompLevel_none;  // Find the max comp level excluding n
  Method* m = n->method();
  // Search for match
  bool found = false;
  while(cur != nullptr && cur != n) {
    if (m == cur->method()) {
      // Find max level before n
      max_level = MAX2(max_level, cur->comp_level());
    }
    last = cur;
    cur = cur->osr_link();
  }
  nmethod* next = nullptr;
  if (cur == n) {
    found = true;
    next = cur->osr_link();
    if (last == nullptr) {
      // Remove first element
      set_osr_nmethods_head(next);
    } else {
      last->set_osr_link(next);
    }
  }
  n->set_osr_link(nullptr);
  cur = next;
  while (cur != nullptr) {
    // Find max level after n
    if (m == cur->method()) {
      max_level = MAX2(max_level, cur->comp_level());
    }
    cur = cur->osr_link();
  }
  m->set_highest_osr_comp_level(max_level);
  return found;
}
```





_i2i_entry指向方法的解释器入口，此值设置后不会再改变



_from_interpreted_entry 初始的值与 _i2i_entry 一样，但后面当该Java方法被JIT编译并“安装”之后，_from_interpreted_entry 就会被设置为指向 i2c_entry





```cpp
class AdapterHandlerEntry : public CHeapObj<mtCode> {
  friend class AdapterHandlerLibrary;

 private:
  AdapterFingerPrint* _fingerprint;
  address _i2c_entry;
  address _c2i_entry;
  address _c2i_unverified_entry;
  address _c2i_no_clinit_check_entry;
};
```







```cpp
class AdapterHandlerLibrary: public AllStatic {
  friend class SharedRuntime;
 private:
  static BufferBlob* _buffer; // the temporary code buffer in CodeCache
  static AdapterHandlerEntry* _abstract_method_handler;
  static AdapterHandlerEntry* _no_arg_handler;
  static AdapterHandlerEntry* _int_arg_handler;
  static AdapterHandlerEntry* _obj_arg_handler;
  static AdapterHandlerEntry* _obj_int_arg_handler;
  static AdapterHandlerEntry* _obj_obj_arg_handler;

  static BufferBlob* buffer_blob();
  static void initialize();
  static AdapterHandlerEntry* create_adapter(AdapterBlob*& new_adapter,
                                             int total_args_passed,
                                             BasicType* sig_bt,
                                             bool allocate_code_blob);
  static AdapterHandlerEntry* get_simple_adapter(const methodHandle& method);
 public:

  static AdapterHandlerEntry* new_entry(AdapterFingerPrint* fingerprint,
                                        address i2c_entry,
                                        address c2i_entry,
                                        address c2i_unverified_entry,
                                        address c2i_no_clinit_check_entry = nullptr);
  static void create_native_wrapper(const methodHandle& method);
  static AdapterHandlerEntry* get_adapter(const methodHandle& method);

  static void print_handler(const CodeBlob* b) { print_handler_on(tty, b); }
  static void print_handler_on(outputStream* st, const CodeBlob* b);
  static bool contains(const CodeBlob* b);

};
```



_from_compiled_entry被初始化为指向c2i adapter stub（方法连接时调用Method::make_adapters()函数设置）），因为方法在开始的时候并没有被JIT编译，只能解释执行。如果从已编译的Java方法调用过来的话就需要适配调用约定。当方法被JIT编译并“安装”完之后，_from_compiled_entry会指向编译出来的机器码的入口，具体说就是指向verified entry point如果要抛弃之前编译好的机器码，那么 _from_compiled_entry 会恢复指向为c2i adapter stub































## Links

- [JIT](/docs/CS/Java/JDK/JVM/JIT.md)
